面试核心技巧 : 
根据面试官的问题 带入自己擅长的知识领域(必须有一个或多个)、或问题。知道就知道，不知道不要瞎蒙
遇到扯淡的人和事 必须要反问回去!!!
用一个东西要知道原理 !!!
每次面试建议录音，并复盘。

InterView

##### JAVA SE 

java 内部类变量为什么使用final修饰?
  这个因为Java inner class实际会copy一份，不是去直接使用局部变量，final可以防止出现数据一致性问题。
JAVA 对象生命周期
  1.create(创建阶段)
  2.In Use(应用阶段)
  3.Invisible(不可见阶段)
  4.Unreachable(不可达阶段)
  5.Collected(收集阶段)
  6.Finalized(终结阶段)
  7.De-allocated(对象空间重新分配阶段)

Collections. 所有的子接口具体实现都实现了 serializable 
  List

  ArrayList 
  底层实现: 数组,通过System.ArrayCopy();实现。
  优点: 通过下标获取元素,速度快。
  缺点: 删除元素、插入元素 必须重新生成新的数组删除耗费性能。 新增元素也有可能会copy数组。
  扩容: ArrayList 扩容容量  size + size >> 1 = size +(size / 2)。

  LinkedList 
  底层实现: 双向链表。其内部结构是 Node<E> 节点 直接new一个Node节点 ,每个节点都有 前驱、prev 和 后继 next 
  优点: 删除、新增速度快。
  缺点: 根据下标遍历,数据量大会慢。如何遍历 ? 根据 index 判断是否 < index/2 for循环遍历最大遍历次数为index ,找到就返回。 如果 index > index/2 则取相反的方式获取元素。
  扩容: 不需要扩容 ,因为其内部结构是 Node<E> 节点 直接new一个Node节点 ,每个节点都有 前驱、prev 和 后继 next 。

  Set
    HashSet
    底层实现: HashMap<E,Object> 实现。放入key的标准与HashMap一致。
    优点: 利用hashMap Key去重,无序,根据hashMap 分布均匀。
    缺点: 不支持排序。不支持下标获取元素。
    扩容: 与HashMap一致。

    TreeSet
    底层实现: TreeMap<E,Object>() 实现。放入key的标准与TreeMap一致。
    优点: 利用TreeMap Key去重,有序,可自定义排序规则。
    扩容: 与TreeMap一致。

Map 
  HashMap
    底层实现: 内部采用数组 + 链表 + 红黑树实现,JDK 8之前没有红黑树。JDK 8 引入了红黑树,引入红黑树的原因是,当数组中某个节点下标存储了多个值，
      此时 hashMap 的遍历方式,会根据链头遍历到链尾。为了解决这个问题 当 tab[i]下的值 大于 8位的时候会自动转换为红黑树。这样遍历速度就很快。

    优点: 根据hash扰动函数能够把数据均匀分散到tab中。通过key 快速获取Val
    缺点: 自动扩容的时候复制麻烦,不支持排序。
    扩容: 当容量等于 75% 会自动扩容。
    默认容量是多少? 1 << 4  16
    最大容量是多少? 1 << 30 
    默认负载因子? 0.75f
    阀值是: capacity * 0.75 元素数量达到这个值后就必须扩容
    红黑树变化数量? TREEIFY_THRESHOLD 树化阈值 8。当单个segment的容量超过阈值时，将链表转化为红黑树。
    什么时候在转化为链表? 链表化阈值 6。当resize后或者删除操作后单个segment的容量低于阈值时，将红黑树转化为链表。
    
    扩容是哪个方法? resize()
    坐标的计算方式? 即下标的获取方式 坐标点的计算方法是e.hash & (cap-1)。 用&运算会提高效率 所以必须是2的n次幂。
    扩容计算方式 : 扩容是按照原容量的2倍进行扩。可以使用按位与替代取模来提升hash的效率。如果在构造函数中指定了Map的大小，那么进行put操作时，初始化后的容量为离传入值最近的2的整数幂，是通过tableSizeFor() 函数达到该目的。总之，容量都是2的幂。为什么capcity是2的幂？因为 算index时用的是（n-1） & hash，这样就能保证n -1是全为1的二进制数，如果不全为1的话，存在某一位为0，那么0，1与0与的结果都是0，这样便有可能将两个hash不同的值最终装入同一个桶中，造成冲突。所以必须是2的幂。
    
    hashMap是如何扩容的?




    JDK 1.7 与 1.8 有什么不同 ?
    
    1. 8时红黑树+链表+数组的形式，当桶内元素大于8时，便会树化
    2. hash值的计算方式不同
    3. 1.7 table在创建hashmap时分配空间，而1.8在put的时候分配，如果table为空，则为table分配空间。
    4. 在发生冲突，插入链中时，7是头插法，8是尾插法。
    5. 在resize操作中，7需要重新进行index的计算，而8不需要，通过判断相应的位是0还是1，要么依旧是原index，要么是oldCap + 原index
    
    讲一下 hashMpa put的方法过程 ?
    
    1.对key求值，计算其在数组中的下标位置。
    2.如果没有hash碰撞直接放入桶中。
    3.如果有hash碰撞接到链表尾部。
    4.如果链表阀值超过8 把链表转换为红黑树。
    5.如果节点存在了就替换旧值
    6.如果桶满了( 容量 * 加载因子) 就对桶resize
    
    hashMap怎么解决冲突 ? 讲一下扩容的过程? 如果tab扩容了原来的值将如何移动 ?
    1. 将新的节点添加到链尾
    2. 扩容到原来的两倍,	然后对每个节点重新计算哈希。
    3. 这个值可能在两个地方,1原来的位置 2. 在下标<原下标+原容量> 的位置。
    
    抛开 hashMap hash冲突有什么解决方案 ?
    1.开放定址法
    基本思想是：当关键字key的哈希地址p=H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中。
    
    2.再哈希法
    这种方法是同时构造多个不同的哈希函数：Hi=RH1（key）  i=1，2，…，k当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。
    
    3.链地址法
    这种方法的基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。
    
    4.建立公共溢出区
    这种方法的基本思想是：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。
    
    为什么是 8的时候会转换红黑树 ?

  ConCurrentHashMap

    不允许插入Null键。
    
    Jdk7 适用了锁分段技术 ,将table 拆分为 16个逻辑数组。每个数组配置一把锁。
    
    Jdk8 取消了锁分段技术, 使用了 CAS + synchronized 使锁粒度更加细化。
    
    JDK8 数据结构与hashMap保持一致 ,有了红黑树。
    
    synchronized 只锁定链表的首节点,只要hash不冲突就不会产生并发。
    
    ConcurrentHashMap put 逻辑
      1.判断 Key是否为 null,如果为空则抛异常。不允许key 为空。
      2.对 Key 求值取下标。
      3.判断Node[]数组是否初始化，没有初始化进行初始化操作。
      4.通过hash定位数组索引坐标,是否有Node节点,如果没有则使用CAS 进行添加（链表的头节点）,添加失败则进入下次的循环。
      5.检查内部是否进行扩容，如果扩容就帮助其扩容.
      6.如果 f!=null ，则使用synchronized关键字锁住f元素(链表/红黑树的头元素)
        4.1 如果是Node则执行链表添加操作。
        4.2 如果是TreeNode则执行树添加操作。
      7.判断链表长度是否已经到达临界值 8 如果达到就转换为树行结构。  


  TreeMap 
  底层数据结构 红黑树 

  设计模式
    单例模式:
      饿汉模式 直接静态生成对象,通过静态方法返回。 缺点 直接生成对象如果没有使用造成内存浪费,当初始化的时候有大量操作会比较慢。 
      懒汉模式 在需要第一次用到对象的时候进行生成。加入了 synchronized,造成性能影响。
      枚举模式 在内部生成枚举,因为枚举本身是单例。在初始化的时候也不会影响性能保证线程安全。不会造成资源浪费。




红黑树
  特殊的二叉树
  1.节点要么是红色，要么是黑色。
  2.跟节点必须是黑色！
  3.红色节点不能连续（也就是 红色节点的子树，和父树都不能是红色）
  4.对于每个节点,从该节点至 null(树尾端)的任何路径,都含有相同个树的黑色节点。每个叶子节点都是黑色的空节点（NIL节点）。
  5.树的结构发生改变的时候（删除或插入） 往往都会破坏 3或4 ,需要通过调整使得查找树重新满足红黑树的条件。

---------------------------------------------------------------------------------------------------------------------------------

04年 JDK 1.5
11年 JDK 7
14年 JDK 8

JRockit 、 Hotspot
JVM(java Virtual Machine ) & GC

##### JVM 内存区域划分

  程序计数器(Pc Program counter register ):
    在JVM规范中，每个线程都会有一个独立程序计数器,并且任何时间都只有一个方法在执行,就是所谓的当前方法.
    程序计数器会存储当前方法正在执行的 java 方法的JVM指令地址。如果是本地方法则是未指定。唯一不会OOM的区域。
  java虚拟机栈(java Virtual Machine Stack ):
    早期的时候叫 java 栈,每个线程创建时候都会分配一个独立的栈空间，内部保存着 一个个的栈帧(stack Frame)。
    对应着一次次的 java方法调用。如果在该方法中调用了其他方法,对应的新的栈帧会被创建出来,成为新的当前栈帧,
    一直到它返回或结束。jvm 对栈的操作只有两个,就是对栈帧的压栈和出栈操作。
    栈帧中存储着 局部变量表,操作数栈、动态链接、方法的正常或异常退出的定义。
  堆(heap):
    jvm 内存核心区域,用来放置分配的java对象。几乎所有的对象都在堆中分配,堆中的对象被所有线程共享。堆分为新生代、老年代。
  方法区(Method Area):
    也是所有线程共享的一块内存区域,用于存储元数据,例如:类的结构信息,以及对应的常量池,字段、方法等代码。
    早起的JVM把方法区成为 永久带,JDK 8 移除了永久代,同时增加了元数据区(MetaSpace)。
  运行时常量(Run-time Constant Pool):
    这是方法区的一部分,Java 的常量池可以存放各种常量信息，不管是编译期生成的各种字面量(String Integer).
    还是在运行时，决定的符号引用。
  本地方法栈(Native Method Stack):
    它和java栈非常相似,也是每个线程都会创建一个。

  可能出现OOM的原因:
    1.堆内存不足是最常见的 OOM 原因之一，抛出的错误信息是“java.lang.OutOfMemoryError:Java heap space”，原因可能千奇百怪，例如，可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理比较可观的数据量，但是没有显式指定 JVM 堆大小或者指定数值偏小；或者出现 JVM 处理引用不及时，导致堆积起来，内存无法释放等。

    2.内存泄漏 当长生命周期对象持有 短的生命周期对象,短的生命周期的对象就无法释放。静态类中的集合、数组、大对象。 静态类和当前应用程序周期一样长,大对象不在使用的时候应该手动至为null,ThreadLocal 中没有调用 remove()方法。
    
    3.而对于 Java 虚拟机栈和本地方法栈，这里要稍微复杂一点。如果我们写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM 实际会抛出 StackOverFlowError；当然，如果 JVM 试图去扩展栈空间的的时候失败，则会抛出 OutOfMemoryError。
    
    4.而对于 Java 虚拟机栈和本地方法栈，这里要稍微复杂一点。如果我们写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM 实际会抛出 StackOverFlowError；当然，如果 JVM 试图去扩展栈空间的的时候失败，则会抛出 OutOfMemoryError。   
    
    5.对于老版本的 Oracle JDK，因为永久代的大小是有限的，并且 JVM 对永久代垃圾回收（如，常量池回收、卸载不再需要的类型）非常不积极，所以当我们不断添加新类型的时候，永久代出现 OutOfMemoryError 也非常多见，尤其是在运行时存在大量动态类型生成的场合；类似 Intern 字符串缓存占用太多空间，也会导致 OOM 问题。对应的异常信息，会标记出来和永久代相关：“java.lang.OutOfMemoryError: PermGen space”。
    
    6.随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的 OOM 有所改观，出现 OOM，异常信息则变成了：“java.lang.OutOfMemoryError: Metaspace”。



JVM 内存结构

方法区: 保存类的原信息 字段方法信息 类型，常量池。JDK 7 已经移动到堆中。
永久代: J7 已经被移除,合并到方法区堆中。

heap(堆): 动态内存,new 出来的对象都会在堆中。 所有线程共享堆内存

stack(栈): 线程私有,由一些列帧组成。 栈保存方法的局部变量(方法参数),操作数栈、常量池指针。 每一次方法调用都会创建一个帧，并压栈。FILO


JMM

 read load use assign store write 
JavaMemoryModel(java内存模型):
  主内存,线程工作内存 保证内存可见性 volatile 、synchronized 、 final 

指令重排: 编译器优化语意 , 指令重排多线程环境会破坏线程的有序性。

X选项
  java -X命令可以看到所有的X选项
XX选项
  这类选项是属于实验性，主要是给JVM开发者用于开发和调试JVM的，在后续的版本中行为有可能会变化。





##### GC 参数:

-verbose:gc 显示GC的情况
-XX:+PrintGC  打印GC
-XX:+PrintGCDetails 打印gc详细信息
-XX:+PrintGCTimeStamps 打印时间戳
-XX:+PrintGCDateStamps 打印日期
-XX:+PrintHeapAtGC  每次GC后，打印堆的信息
-XX:+TraceClassLoading 监控每一个类的加载
-XX:+PrintClassHistogram 打印类的使用情况,按下 Ctrl+Break后才会打印。
-Xloggc:/Users/vergil/Documents/gcLogs/gc.log 保存GC log

-Xmx: 指定最大堆空间(最大可用)
-Xms: 至少使用空间(初始化大小)

  MetaspaceSize 默认20M
-XX:MetaspaceSize=100M(元数据空间大小)
-XX:MaxMetaspaceSize=100M（元数据空间最大）

-XX:PretenureSizeThreshold
  这个参数只对 Serial 和ParNew两个收集器有效
  默认是0(不管占用大多内存空间都先分配在eden)，当值大于0,内存大小超过这个值就会直接分配到老年代

-XX:+PrintTenuringDistribution
  让JVM在每次MinorGC后打印出Survivor空间中的对象的年龄分布。

-XX:MaxTenuringThreshold=X 
  X默认是15，15的含义是从eden-->survivor 对象年龄+1，survivor-->eden 对象年龄+1，直到年龄达到15后开始进入old Generation。

-XX:+UseGCLogFileRotation 
  打开或关闭GC日志滚动记录功能，要求必须设置 -Xloggc参数
-XX:NumberOfGCLogFiles=5 
 设置滚动日志文件的个数，必须大于1 日志文件命名策略是，<filename>.0, <filename>.1, ..., <filename>.n-1，其中n是该参数的值
-XX:GCLogFileSize=5m
 设置滚动日志文件的大小，必须大于8k 当前写日志文件大小超过该参数值时，日志将写入下一个文件




-Xmn: 设置新生代绝对大小
-Xms: 设置初始化堆大小
-Xmx: 设置堆最大内存
-Xss 栈空间分配 通常只有几百k ，决定了函数调用的深度。

-XX:NewRatio 1:4 设置新生代比例值
-XX:SurvivorRatio 设置两个Survivor区和eden的比 eden=2:8
-XX:+HeapDumpOnOutOfMemoryError 导出OOM文件
-XX:HeapDumpPath 导出OOM路径 
-XX:OnOutOfMemoryError  在OOM时候执行一个脚本。


-XX:+UseSerialGC: 串行收集器
-XX:+UseParNewGC: 新生代并行收集器。
  -XX:ParallelGCThreads 限制线程数量。
-XX:+UseParallelGC: 并行收集器。
-XX:+UseParallelOldGC: 老年代并行收集器
-XX:+UseConcMarkSweepGC: 老年代并发标记清除收集器。
  -XX:UseCMSCompactAtFullCollection Full GC后，进行一次整理内存碎片
  -XX:CMSFullGCsBeforeCompaction  设置进行几次full GC 后,进行一次碎片整理
  -XX:ParalleclCMSThreads 设定cms线程数量。

-XX:+UseG1GC 开启G1垃圾收集器
  -XX:MaxGCPauseMillis=200 设置最大停顿时间为200ms





官方推荐新生代配置
新生代占用堆的 3/8
幸存代占用新生代的 1/10




CommandLine flags: 

-XX:InitialHeapSize=536870912 
-XX:MaxHeapSize=536870912 
-XX:MaxNewSize=3145728 
-XX:NewSize=3145728 
-XX:+PrintGC 
-XX:+PrintGCDetails 
-XX:+PrintGCTimeStamps 
-XX:+UseCompressedClassPointers 
-XX:+UseCompressedOops 
-XX:+UseParallelGC 



eden  s0(from)  s1(to)   tenured(Old Gen)
GC  (garbage Collection) 垃圾收集 :

根据对象的存活周期进行分类,短对象归新生代,长对象归老年代。

多次 gc 没有回收，就会进入老年代。

finalize() 调用次方法可能会复活该对象。

判断对象为垃圾的两种方式
  引用计数器算法
  可达性分析
    GC Root: 
      栈中引用的对象。 
      方法区中静态成员变量常量。 
      全局对象。
      JNI方法栈中引用对象。

清理Eden区和Survivor区叫Minor GC；清理Old区叫Major GC；清理整个堆空间—包括年轻代和老年代叫Full GC。  

Minor Gc
  新生代的gc 清理Eden区和 Survivor区叫Minor GC。
Major GC
  老年代的清理
FullGC
  新生代，老年代空间不足会出发FullGC 。

STW(Stop-The-World)
  Gc线程暂停全部进行标记
  java中全局暂停的现象。
  全局停顿,所有java代码停止,native代码可以执行,但不能和JVM交互。  
  多半是由GC 引起的 。 Dump线程  死锁检查 Dump堆 都有可能 STW
  长时间服务停止，没有响应。 集群环境中可能存在未知问题 比如主从切换。服务无法被注册中心感知。






判断对象是否可用:
  引用计数法(没有被使用): 为对象标记引用数量,无法判断对象循环引用。引用和去引用伴随着加减法,影响性能。
  可达性分析:根据 GC Root 取关联查找位于链中的对象是否还会被引用,如果没有被引用则会标记为不可达对象。

GC算法 & GC种类

标记清除(Mark-Sweep): 
  标记清除算法，分为两个阶段 第一个阶段标记,第二个阶段清除.
  会产生内存碎片,当一个大对象需要连续的内存空间，从而会再次触发GC。

复制算法(Copying): 
  把新生代 Suvoriver内存划分两个(s0,s1)同样大小的区域,每次都使用其中的一块内存,当这块内存用完了，就会复制存活对象到另外一块内存空间，清除当前内存空间。
  分配内存不用考虑内存碎片问题，简单高效。
  当内存空间过大的时候，会浪费内存空间。

标记压缩(Mark-Compact):
  执行过程于标记清除一致,最后一步会做移动把存活对象向一端移动,直接清理边界以外的内存。




Serial(串行回收器):
 古老，稳定，效率高
 可能会产生较长时间的停顿,会暂停工作线程,只有一个线程进行回收。
 -XX:+UseSerialGC
  -新生代、老年代都可使用串行回收 关键字: GC DefNew 新生代 Full GC 老年代
  -新生代复制算法
  -老年代标记-压缩

ParNew(并行收集器):
 多线程回收,只适用于新生代 采用复制算法。会暂停应用线程。 关键字:ParNew 
 复制算法
 -XX:+UseParNewGC
  新生代并行,老年代串行。
  -XX:ParallelGCThreads 限制线程数量。

Parallel Scavenge(并行收集器):
  Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。  
  类似于ParNew
  新生代复制算法,老年代标记-压缩.更加关注吞吐量。会暂停线程。
  -XX:+UseParallelGC     关键字: PSYongGen 
    使用Parallel收集器+老年代串行。
  -XX:+UseParallelOldGC  关键字: ParOldGen
    使用Parallel收集器+并行老年代。

CMS收集器:
  Concurrent makr sweep 并发标记清除。伴随应用线程并发交替执行。
  并发阶段会降低吞吐量。
  使用标记-清除算法
  清理不彻底，因为和用户线程并发执行。会产生碎片。
  老年代收集器,新生代会使用ParNew。

  CMS FullGC:
  CMS 有可能造成FullGC的原因 是清理内存后有连续的碎片。当大对象分配的时候可能造成内存不足。
  如果没有配置清理碎片，始终保留内存碎片。Concurrent mode failure 当回收失败的时候 会切换为
  串行回收器。串行回收器回收可能导致GC时间大量停顿。因为碎片无法清除 可能会造成FullGC。

  如何 解决上述为题?
     XX:UseCMSCompactAtFullCollection Full GC后，进行一次整理内存碎片
    -XX:CMSFullGCsBeforeCompaction  设置进行几次full GC 后,进行一次碎片整理


  -XX:+UseConcMarkSweepGC  关键字: CMS
    -XX:UseCMSCompactAtFullCollection Full GC后，进行一次整理内存碎片
    -XX:CMSFullGCsBeforeCompaction  设置进行几次full GC 后,进行一次碎片整理
    -XX:ParalleclCMSThreads 设定cms线程数量。



  回收过程
    初始化标记
      由GCROOT向下初始化标记,会产生全局停顿,标记速度快。 
    并发标记(并发)
      主要标记过程,和应用线程共同执行。标记全部对象。
    重新标记
      由于并发标记，应用线程仍在运行。在清理之前需要修正。重新标记。会产生停顿。
    并发清除(并发)
      基于标记结果直接清除被标记对象。 和应用线程一起      





G1(garbage first): 垃圾收集器
  JDK 7 新增收集器.
  使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。
  尽量缩短处理超大堆（大于4GB）时产生的停顿。

  老年代的物理空间划分取消了。
  G1算法将堆划分为若干个区域（Region），它仍然属于分代收集器。

  空间整合
    G1收集器采用标记整理算法，不会产生内存空间碎片。
  可预测停顿
    G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内。  
  收集步骤: 
    1.标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark)
    2.根区域扫描(Root Region Scanning):程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。
    3.并发标记(Concurrent Marking):在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。
    4.重新标记(Remark): 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。

​		5.复制清除(Copy/Clean up): 多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。

class装载流程
  加载
    获取类的二进制流。
    转为方法区的数据结构
    在java堆中生成对应的java.lang.Class对象 

  链接
    验证
      文件格式校验: 版本号是否合理。是否以0xCAFEBABE开头。
      元数据校验: 是否有父类 继承了final类?非抽象类实现了所有的抽象方法。
      字节码校验: 非常复杂 运行检查。
      符号引用校验: 访问的字段方法是否有权限。
    准备
      分配内存,并为类设置初始化值(方法区中)。
      static v =1;在准备阶段赋值为0 , 初始化阶段才为1。
      static final v=1; 在准备阶段就为1 因为是final修饰。
    解析
      符号引用替换为直接引用(指向目标的指针)。

  初始化
    执行类构造器<clinit> static变量赋值, 执行静态代码块 static {} 语句执行。
    子类的<clinit>执行之前,父类的<clinit>会先执行。


LoadClass和forName的区别:
ClassLoader.loadClass(String className) 不会初始化类 ,即不会执行静态代码块。
Class.forName(String className) 会初始化类,即会执行类的static {} 静态代码块。


ClassLoader:
  ClassLoader负责类装载过程中的加载阶段。
  ClassLoader是一个抽象类
  ClassLoader的实例将读入java字节码将类装载到JVM中
  ClassLoader可以定制,满足不同的字节码流获取方式

  BootStrap ClassLoader: 启动类加载器。 加载 rt.jar
  Extension ClassLoader: 扩展类加载器。 加载 %JAVA_HOME%/lib/ext/*.jar
  Application ClssLoader: 应用类加载器/系统类加载器 加载 classPath:下
  Custom ClassLoader: 自定义类加载器
  每个ClassLoader都有一个Parent作为父加载器。
  双亲加载模式是默认的，但不是必须的。tomcat WebappClassLoader 就会首先加载自己的Class
  自底向上检查类加载器是否已经加载。



##### 线程和并发

Thread
  常用方法:
    join(): 当一个线程调用了另外一个线程的join方法,当前线程会被挂起处于阻塞状态,直到另外一个线程执行完毕。
    yield(): 静态方法 当前线程调用了yield方法后,当前线程会让出CPU时间片,重新回到等待区进行与其他线程再次争夺CPU时间片,有可能还是当前线程获取到时间片。
    isAlive(): 判断当前线程是否存活。
    dumpStack():打印堆栈信息
    setDaemon():设置守护线程,守护线程会随着用户的线程消亡而消亡。
    sleep():静态方法 让当前线程休息指定的时间,如果当前线程持有锁，不会释放锁。
    interrupt():将一个线程的 状态标识设置为Interrupted状态仅此而已。
       1.如果线程处于被阻塞状态,sleep、wait、join立即退出阻塞状态,将会抛出 InterruptedException异常。
       2.如果线程处于正常活动状态,线程中断标志将会设置为true，线程将继续运行不受影响。
       3.配合中断标志可以优雅的让线程退出。
  死锁: 
    互斥条件
    请求和保持资源
    不剥夺条件
    环路等待条件


    如何避免死锁: 使用有时间限制的锁
    如何检测死锁: 使用Jsatack 或者 ThreadMXBean

堆栈封闭:
  方法体内的变量，都会在栈中拷贝一份不会被线程共享。
  ThreadLocal 线程封闭
创建线程的方式:
  1.继承Thread接口,或者实现 Runnable接口。 这种方式不会有返回值
  2.实现 Callable 和 Future 或者继承 FutureTask
Runnable、Callable 、Future FutureTask 有什么区别?
  Runnable: 不会返回结果
  Callable: 会返回线程执行完毕的结果
  Future: 获取返回值的接口
  FutureTask: 实现了Future接口 获取Callable中的返回值



https://www.cnblogs.com/java-spring/tag/%E5%A4%9A%E7%BA%BF%E7%A8%8B%26amp%3B%E9%AB%98%E5%B9%B6%E5%8F%91/


Object
  对象头(MarkWord):
    用于存储对象自身的运行数据,如hashCode、GC分代年龄、锁状态标志、线程持有锁、偏向线程ID。
    lass指针: 即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象属于哪个类的实例；
    length: 如果是java数组，对象头必须有一块用于记录数组长度的数据，用4个字节来int来记录数组长度；
  实例数据(Instance Data):
    对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。
  对齐填充(Padding):
    并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。
    




Object object = new Object();
  1. memory = allocate() //分配内存空间
  2. createInstance() //初始化对象
  3. instance = memory 设置指针指(引用)向内存
    当JVM和CPU 发生指令冲排序后，上述操作不会按照顺序执行。即多线程环境下，非线程安全???  




四种引用:
  不同类型的引用主要体现在对象的可达性状态,和对垃圾回收的影响。

  强引用(StrongReference):
    回收时间: 一致存活,除非 GC Roots 不可达
    应用场景: 所有程序的场景，基本对象，自定义对象等
  软引用(SoftReference):
    回收时间: 内存不足时会被回收   
    应用场景: 一般用在对内存非常敏感的资源上，用作缓存的场景比较多，例如：网页缓存、图片缓存
  若引用(WeakReference):
    回收时间: 只能存活到下一次GC前 
    应用场景: 生命周期很短的对象，例如ThreadLocal中的Key。
  虚引用(PhantomReference):
    回收时间: 随时会被回收， 创建了可能很快就会被回收  
    应用场景: 可能被JVM团队内部用来跟踪JVM的垃圾回收活动 netty的内存泄漏检测中使用到：ResourceLeakDetector中的ResourceLeak



线程安全三个要素:
  原子性:提供了互斥访问,同一个时刻只有一个线程操作。
  可见性:一个线程对主内存进行修改，其他线程会立刻观察到
  有序性:处理器会优化执行顺序,叫做指令中排序。指令冲排序不会影响单线程。一个线程观察其他线程指令顺序,由于指令 冲排序的存在,该结果一般杂乱无序。


什么是悲观锁?乐观锁

悲观锁,乐观锁是一种概念。
  悲观锁: 始终认为会发生冲突,会屏蔽一切违反数据完整性的操作,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如RetreenLock。
    jdk实现: synchronized 、Lock
  乐观锁: 假定不会发生冲突,在实际操作会检查是否违反数据完整性，如果操作失败会执行重试。
    CAS(Compare And Swap) :比较交换


CAS(Compare And Swap):

  CAS 会利用CPU的一些特殊指令。会保证原子性。Unsafe(硬件级别的原子操作)工具直接操作内存

  包含三个操作数 内存位置(主内存值)V 预期原值 A 新值B,当 A == V 才执行V = B,否则不做操作。
  缺点:
    若循环时间长,则开销很大。
    只能保证一个共享变量的原子操作
    ABA 问题。解决ABA问题 AtomicStampedReference 


  线程常用的方法
  join: 当前线程调用了另外一个线程的join方法，当前线程就会wait 等待另外一个线程执行完毕，才会执行当前线程。
  yield : 当前线程让出CPU执行时间片,由 运行状态 变为 就绪状态,与其他线程再次争抢CPU时间片。即yield方法并不能完全让出CPU时间片。

  sleep
  dumpStack 




  ThreadLocal


  在Spring 中的应用 RequestContextHolder 、DateTimeContextHolder 、

  Thread中的成员变量ThreadLocalMap 中存储了ThreadLocal

  当一个线程运行完成后会被JVM回收,threadLocal就会被回收了。当我们在使用线程池的时候，某些线程池不会被回收线程。
  在ThreadLocal 调用 Set、remove、rehash 会扫描key为null的Entry,并且把对应的Value 设置为null。

  如何避免内存泄漏? 调用remove 

  ThreadLocal 中的Key是一个弱引用,value 是一个强引用
    弱引用的特点是，如果这个对象只被弱引用关联（没有任何强饮用关联）,这个对象就可以被回收。

    ThreadLocal处理hash冲突与hashMap有什么不同 ?
      hashMap 使用拉链法，红黑树解决hash冲突。
      threadLocal 使用向下寻找空位置填充，没有链表
    
    ThreadLocalMap中存储的是key是ThreadLocal value 可以是任意Object 
    ThreadLocalMap 中为什么不把线程ID 当作key 存储? 因为这样每个线程只能存储一个 key,value
    
    ThreadLocal 原理: 
    线程隔离
    
    概述: ThreadLocal的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。
    
    内部结构: ThreadLocal.ThreadLocalMap 与线程关联是 Thread.ThreadLocal.ThreadLocalMap
    
    内存泄漏(memory leak): 因为使用了若引用导致 在下一次GC Key 被回收 无法在获取Value 这样 value 一直存在 引用链和线程就会一直存在,
    即使使用强引用也是会出现内存泄漏. thread -> threadLocalMap -> Entry ->key.value
    
    为什么使用弱引用: 因为 如果设计成强引用 key 就永远不会回收,调用链的方式就会导致 thread threadLocal Entry 都不会回收。
    当设计成 弱引用的时候,如果某个线程生命周期较长,当他调用了 get set remove 的时候就有可能会清除为key == null 的 entry 因为是迭代所以不确定是不是每次都会清除。
    
    实际应用场景:


      1.每个线程内需要保存全局变量,可以让不同的方法直接使用。避免参数传递的麻烦。
      2.每个线程需要独享的对象(通常是工具类 比如 SimpleDateFormat、Random)
    
      如果Service中需要获取UserID,就必须从HttpRequest中取出来向下传递。向下传递的过程中可能需要多次传递有可能需要到Util中。
      把UserId 放入ThreadLocal中每个线程进来处理请求就会从线程中获取UserId，很方便。ThreadLocal在使用完以后需要remove里面的对象,
      否则将会导致内存泄漏? 通过测试 在Filter中set 一个50M的字节数组,不做remove操作真的会出现内存泄漏的问题。






  happen-before:
    1.程序顺序原则: 一个线程内保证语意义的串行,即单线程环境不会冲排序不会影响结果。
    2.volatile规则: volatile修饰的写发生在读之前,保证了可见性
    3.锁规则: 解锁必然发生在加锁之前。
    4.传递性: A先与B,B先于C,那么A必然先于C
    5.线程的start 方法必须优先于它的每一个动作
    6.线程所有的操作优先于线程的结束
    7.线程的终端 先于被中断之前的代码
    8.对象的构造方法执行结束先于finalize() 方法。


  volatile 符合 happens-bofer 原则2

  volatile

     Memory Barrier: 内存屏障 CPU指令
     1.保证操作执行顺序
     2.保证某些变量的内存可见性
    
     通过插入内存屏障指令,禁止在内存屏障前后的指令执行重排优化。
     强制刷出各种CPU的缓存数据，因此任何CPU线程都能读取到这些数据的最新版本。



    对变量的写操作不依赖于当前值
    该变量没有包含在其他变量的,对变量赋值 是原子操作。
    double check 双重检查,单例模式下的安全手段。
    volatile 会禁止指令冲排序。再多线程环境下顺序执行,无法保证原子性依然有并发问题。
    volatile 只能保证可见性,并不能保证原子性。
    即 i++ 是非原子操作,用volatile 修饰后依然无法保证原子性，故多线程环境下依然有并发问题。
    boolean flag ; 变量赋值具有原子操作,用volatile修饰 boolean 可以适当的控制线程安全。
    
    volatile 可见性: 会强制别的线程读取 主内存
    volatile 有序性: 遵循happens-before原则 禁止指令重排，保证CPU不会乱序执行

  

  synchronized

    A obj = new A();
    
    sychronized(obj) {
        xxxx
    }
    上述代码锁住了是 obj对象还是 xxx 这段代码。
      synchronized 锁的是对象。


    对象布局:
      对象头markWord : 
         MarkWord:类型、GC状态、synchrozied状态、hashcode
         klass point 或者 Class MetaData Address : 储存对象类型数据的指针。 
    
      实例数据:对象实际大小
      对齐填充: 8的倍数分配, 比如 申请了 10byte 会分配16byte。






    synchronized 不会禁止指令冲排序 ！
    
    对象的创建分为三部:
    1.memory = allocate(); // 1.分配对象内存空间
    2.instance(memory); 初始化对象
    3.instance = memory; //设置 instance 指向刚分配内存地址，此时instance != null
    由于 2 、3 不存在数据依赖关系，可能会发生指令重排。 



锁:

每个对象天生自带Monitor锁。

Monitor: 

monitorEnter: 加锁 
monitorExit: 释放锁

对象头
Mark Word: 对象头标记 
  存储对象的hash、锁信息、垃圾回收标记，年龄
  指向锁记录的指针,
  指向monitor的指针
  GC标记
  偏向锁线程ID

ClassMetaDataAddress 类型指针指向对象的类元数据,JVM通过这个指针确定对象是哪个类的数据。

实例数据

对齐填充 






synchronized锁，可分为偏向锁、轻量级锁、重量级锁。

在jvm没有显示关闭偏向锁的情况下，初始状态时默认是偏向锁时，

线程请求先通过CAS替换mark word中threadId,如果替换成功则该线程持有当前锁。

如果替换失败，锁会升级为轻量级锁，
线程请求会尝试CAS替换mark word中指向栈中锁记录的指针，如果替换成功则该线程持有当前锁。

如果替换失败，当前线程会自旋一定次数，继续尝试获取CAS替换，如果超过一定自旋次数，锁升级为重量级锁。



synchronized锁是调用系统内核互斥锁实现的，线程在获取synchronized锁失败后，也会进入一个等待获取锁队列中（系统内核实现的），
线程会由运行态切换到阻塞态，让出CPU，待其他线程释放锁后唤醒它。

synchronize锁重（1.6之后jvm有优化）就是重在两点，一是调用内核互斥锁实现，二是线程获取锁失败会变成阻塞态，让出CPU，等待唤醒（有一定的上下文切换）  



JDK 获取锁首先尝试 偏向锁,偏向锁不可用会尝试轻量级锁，轻量级锁不可用会尝试获取自旋锁,自旋锁获取失败会膨胀为重量级锁。

如何优化代码
  减少锁持有时间,即synchronized 只同步需要线程安全处理的对象。
  减小锁的力度 ,大对象拆分小对象。jdk 1.7 ConcurrentHashMap中把数组拆成了 Segment 先定位到一个Segment再去操作。  


偏向锁:
  偏向锁失效:
    1. 在sycnhronized方法前面,计算hashcode 会导致markword 存不下线程id。
  当线程中该线程已经获取过锁，就会偏向于当前线程。
  在激烈的线程竞争，偏向锁会增加系统负担。
  适用场景: 适用于固定线程池里面的线程,如果是http线程每次请求都是新的线程。
  ? 那么是不是也适用于异步的线程呢 即 异步操作只有少量的固定线程。

轻量级锁(BasicObjectLock):
  放在线程栈中的锁。
  如果对象没有被锁定,将对象头mark指针保存到对象中,将对象头设置为指向锁的指针。
  偏向锁运行在同一个线程进入同步块的情况下,第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁。
  适用场景: 线程交替执行的代码块。


自旋锁:
  JDK 7 默认实现。
  线程空转,类似于循环但是不会参与线程间的竞争,减少线程之间的上下文切换。
  如果同步块执行的时间比较长,自旋锁会失败。反之会提高系统性能。
  适用场景: 加锁的代码块执行的时间比较短,即短事物操作。



锁分离:
  读写锁ReadWriteLock。
  读多写少的情况下可以提升性能。读的时候拿取读锁,写的时候拿取写锁。

锁消除:
  在方法内使用StringBuffer 不会进行加锁操作了。编译器优化 🧬

锁粗化:
  在方法内使用循环StringBuffer,如果该变量是实例变量（即确实存在线程安全问题）synchronized会被移动到循环外部,也是编译器优化。  



无锁:
  无锁是一种乐观操作。
  经典实现 CAS 内部使用Unsafe     

  ThreadPool

    线程池组成部分:
      线程池管理器
      工作线程
      任务队列
      任务接口
    
    原理:
    
    线程池的关闭: 调用shutdown()方法 并不会立即停止线程。等待所有任务执行完毕后才会关闭.
    
    使用场景: ScheduledThreadPool 代替简单的定时任务
    
    拒绝策略: RejectHandler 
      AbortPolicy : 直接抛异常。 当任务超过最大线程数，并且阻塞队列任务已满。
      DiscardPolicy : 丢弃任务。 丢弃任务
      DiscradOldestPolicy : 丢弃老的任务
      CallerRunsPolicy : 提交任务的线程 去执行任务




    线程池的核心参数设置:
    核心数如何设置最好,根据提交任务种类进行设置。
    CPU 密集型任务(加密、hash、压缩): 最佳显线程数 CoreSize = 核心数的 1-2 倍即可。太多了CPU会负载过高。
    IO 密集型 (读写文件、数据库、网络): 最佳线程数 一般大于CPU核心数很多倍,以JVM 线程监控显示繁忙情况为依据,保证线程可以衔接上。
    参考 Brain Goetz 推荐的计算方法 : 线程数 = CPU核心数 * （1 + 平均等待时间/平均工作时间）
    然后根据压测数据去计算适当的核心线程数。



    核心接口(类):
      Executor: 线程池执行任务基础方法
      ExecutorService: 提供了任务,线程池生命周期的扩展。
      SecheduledExecutorService: 提供了定时调度的线程池任务。
      ThreadPoolExecutor: 线程池核心处理类，实现了所有的线程池方法。
      Executors: 线程池创建工具类。单例 借助 ThreadPoolExecutor 实现几种常用的线程池。
    常见线程池:
      Executors.newCachedThreadPool: 可缓存的线程池,根据线程池的繁忙程度。coreSize:0 maxSize:Integer.MAX_VALUE; 空闲60s
        阻塞队列: SynchronousQueue
      Executors.newFixedThreadPool: 固定线程数的线程池。coreSize maxSize 都是固定数量。
        阻塞队列: LinkedBlockingQueue
      Executors.newSingleThreadExecutor: 单个线程的线程池。
        阻塞队列: LinkedBlockingQueue
      Executors.newScheduledThreadPool: 固定的可调度的线程池。
        阻塞队列: DelayedWorkQueue
    
    线程池好处: 
      重用存在的线程，避免线程重复的创建、销毁 等开销。
      有效控制最大线程数,提高系统资源利用率。提供多样化的控制线程数。
    核心实现类:
      ThreadPoolExecutor
        corePoolSize: 核心线程数
        maximumPoolSize: 最大线程数
        workQueue: 阻塞队列,存储等待执行的任务,又对线程池产生重大影响。
        keepAliveTime: 线程池允许空闲线程的空闲时间。
        threadFactory: 线程工厂,用来创建线程。
        rejectHandler: 当阻塞队列，和 最大线程数满的时候会有一定侧策略。也可以自定义策略。
    线程池状态:
      Running: 线程运行状态，处理workQueue中的任务。
      shutdown: 不能在接受新的线程任务,但是可以处理workQueue中已有的任务。处理完成后关闭线程池。
      stop: 不接受新的任务，也不会处理workQueue中的任务。中断线程池中正在处理的内容。
    常用方法:
      execute: 向线程池提交任务。
      submit: 提交任务，能够返回执行结果。
      shutdown: 关闭线程池。
      shutdownNow: 关闭线程池,即使有在执行的任务也关闭。
      getTaskCount: 线程池执行和未知性的任务总数。
      getCompletedTaskCount: 已完成的线程数量。
      getPoolSize: 获取当前线程池中的数量。
      getActiveCount: 当前线程池中正在执行的线程数量。         




JUC: 

AQS(AbstractQueuedSynchronizer):

  AQS 核心 : State 、FIFO队列、


  CountDownLatch(闭锁): ,通过一个计数来保证线程是否阻塞。计数不可重置。
    应用场景: 多个线程必须等待某些线程完成以后才能做处理等情况。
  Semaphore(信号量): 控制同一时间线程并发的数量。
  CyclicBarrier: 与countDownLatch 差不多功能更强大.
    应用场景: CyclicBarrier常用于多线程分组计算。
  ReentrantLock: AQS 锁。   
  FutureTask: 


  atomicInteger:
    使用了CAS操作,有点类似于 自旋锁。不停的循环操作。
  CountDownLatch: 
     应用场景: 在做分布式锁需要用CountDownLatch 夯住线程。  
  Semaphore: 信号量 像是一个许可证.线程执行完毕后会还回许可证。在同一个时刻能控制少量的线程进行并发
     

 BlockingQueue:
   如果队列为空,获取队列会一直阻塞，直到里面有了数据。如果队列满了 插入就会阻塞 。直到有多余空间。(生产者消费者模型)







##### Redis

redis :
  存储类型:
    String:
      desc: 最基本的数据类型，二进制安全。不仅限于 存储 String。最大存储512M.
      ops: set [key,val] 会覆盖数据 get[key] incre[key]自增 setnx [key,val] 如果存在则返回,不存在则返回0。
      经典实现: 自增数实现分布式全局ID 各种访问数量,如 用户访问量,点赞。字符串用来存储 token , 短信验证码之类。
      底层实现: Sds(SimpleDynimicString)简单动态字符串 sds [int len, int free char [] buffer] 
      通过len字符串长度而不根据\0作为结束,每次扩容都把buffer数组 扩容至原来的一半。free 表示长度的/2

    Hash(字典):
      desc: 存储类型类似于对象。hmset创建对象。 通过hget hset 获取对象。
      ops: hmset key [filed,val],[filed,val],[filed,val]. hget obj.filed. hset obj.filed
      经典实现: json序列化的对象存储,购物车实现。
      底层实现:  
    List(列表):
      desc:  按照插入的String元素排序,后进先出 (stack)的数据结构。可以存储40亿成员。O(1) 复杂度
      ops: lpush [key,val]。 lrange [0 n] 取数据
      经典实现: 最新消息排行榜。
      底层实现: 双向链表和ziplist 
    Set(集合):
      desc: 集合,类似于java List 无序，通过hash表实现。不允许重复。
      ops: sadd [key,val] 添加集合元素, smembers [key] 获取集合。
      经典实现: 把关注人存在set中.可以 求交集、并集、差集。操作 计算共同关注。
    StoreSet(有序集合):
      desc:  会记录一个double类型的 score ,按照从小到达排序。score可以重复,Value不允许重复 分数小靠前。
      ops: zadd [key,score,value] zrangebyscore [key 0,n]
      经典实现:排行榜、存储班级学生成绩排序。程序根据重要的任务排序,score 高的任务优先执行。
      底层实现:跳跃表 1.实现有序集合键 2.集群节点中用作内部数据结构
    HyperLoglog: 计数
    GEO: 地理位置存储、搜索、计算。

   经典实现:
     缓存
     分布式id
     海量数据统计: 
       位图(bitMap) : 存储是否是否参加过某活动、读过某文章、是否为会员、日活统计、文章点赞取消点赞。
       语法: setbit key offset value 
         点赞: setkey wz2 10010 1  :wz2 是文章标题与id 10010是用户id ,1 是value。bitcount 可以统计出来一共点赞数。又不会重复点赞
         日活: 
       栗子🌰: 
     回话缓存: session
     分布式队列/阻塞队列:
       List是一个双向链表,可以通过lpush/rpush和 rpop/lpop 写入和读取消息。可以通过用brpop/blpop来实现阻塞队列。
       lpush list a b c ltrim 从左边截取最新的数据。可以做热点数据。
     分布式锁: 
       SETNX 
     热点数据存储:
       最新评论,最新文章列表,使用list存储,ltrim取出热点数据，删除老数据。
     社交类需求:
       Set可以实现交集,共同好友列表。Set 求差集,可以进行好友推荐,文章推荐。
     排行榜:
       Zset 可以实现有序操作,从而实现排行榜
     延迟队列:
       store_set    


   底层数据类型:
     简单动态字符串
     链表
     字典
     跳跃表
     整数集合
     压缩列表
     对象

  sharding(分片):

  缓存数据一致性: 通过MQ 监听某更新或删除操作。当数据发生变化的时候去更新最新的缓存.

  缓存并发问题: 缓存过期,大量请求访问db ，这个时候会用一个加锁的方式去更新缓存剩余请求就可以正常获取缓存了。

redis 面试题
  Redis 为什么快?
    客户端单线程，避免上下文切换。
    服务器采用IO多路复用。
    RESP(Redis Protocol Specification)协议: RESP实际上是一个序列化协议，它支持以下数据类型:简单字符串、错误、整数、大容量字符串和数组。 
  如何持久化
    RDB: 保存一个时间点之前的快照数据。 手动出发bgsave
    AOF: 所有写操作以命令方式 持久化。
  Redis 如何处理过期数据
    惰性删除: 访问数据过期才会删除
    定期删除: 定期删除 通过serverCron 任务执行 持久化、定期删除

  缓存击穿(穿透): 当某个缓存过期，大量请求直接打到数据库中。而数据本身就是空(空集合|null) 
    1.对查询结果为空的结果依然缓存
    2.对数据可能为空的Key做拦截。
  缓存雪崩: 
    1.上述情况大量请求直接打到数据库中。固定的时间内有大批量缓存失效(避免缓存集中失效)。
    2.把大量的热key 尽量缓存到本地。

  缓存策略:
    定时剔除:设置过期时间剔除。
    主动更新:通过消息、或其他方式主动更新缓存。

  内存不够的时候如何删除:



  Redis (内存超过 maxmemory)过期策略: 
    noeviction : 不会继续写请求,(Del 请求可以继续服务) ,读请求可以继续进行。默认的淘汰策略
    volatile-lru : 尝试淘汰设置了过期时间的key,最少使用的key优先被淘汰。没有设置的过期的key不会被淘汰。
    volatile-ttl: 跟上面一样,除了淘汰策略不是LRU,而是key剩余ttl的值,值越小优先被淘汰。
    volatile-random: 随机淘汰过期集合中的key
    allkeys-lru: 淘汰所有对象key 集合，无论是否过期。
    allkeys-random : 随机淘汰所有key



  缓存失效算法剔除(高级)
    LRU(Last Recently Used)
      最近最少使用。判断最近被使用的时间，目前最远的数据优先被淘汰。
    LFU(Last Frequently Used)
      最不经常使用的优先淘汰。在一段时间内，数据被使用次数最少的，优先被淘汰。
    FIFO
      先进先出。判断被存储的时间，离目前最远的数据优先被淘汰。  

redis -> 单线程? -> reids 在处理客户端请求的时候是单线程，在执行io操作会fork子线程。  
redis IO 多路复用

分布式:
  分布式锁
    redisson
  分布式调度
    Elastic-Job
  分布式事务
    tcc-transtrion
    Consistency 一致性
    Availability 可用性
    Partition tolerance 分区容错性
    这三个指标不可能同时做到。这个结论就叫做 CAP 定理。

  一致性hash

##### Spring

  Spring 循环依赖问题 
    AllowCircularReferences  默认是true

    三个条件 1.Singletone 2. allowCirularRefrences 3.isSingletoneCreation
    
    如果 spring 允许 上述条件,会把bean放入 singletonFactories 中。
    
    一级缓存 singletonObjects(Map) 存放单例的bean 是经过spring生命周期创建的Bean 不是反射创建的对象。
    二级缓存 singletonFactories(Map) 
      二级缓存中存储的是 String name K(对象), ObjectFactory<?>V（对象工厂 是一个labmbda）,这个对象工厂 是根据 对象通过反射创建后 有一个判断是否允许循环依赖(allowCirularRefrences)
      为什么不直接 存储对象而是工厂?
         1.如果对象中需要用到ApplicationContext,此时这个对象并没有走完Spring Bean 生命周期,ApplicationContext 是为null的。
         2.ObjectFactory 工厂可以随时创建Bean,更加灵活。
    
    三级缓存 earlySingletonObjects(Map) 主要放半成品的Bean
      执行二级缓存会把ObjectFactory.getObjects 对象(此时还不是Bean,所以叫半成品的Bean),放入三级缓存。
      为什么要把 这个对象添加到三级缓存中?
        因为一开始，是从三级缓存直接获取对象。是为解决更长的循环依赖比如 A->B-C-A
      添加到三级缓存中以后，二级缓存调用了singletoneFactories.remove(name) 把二级缓存对象删除了
        为什么要删除二级缓存中的对象?
          因为GC，如果不删除的话 那就是有内存泄漏。


  BeanFactory 和 FactoryBean 有什么区别 ?
     BeanFactory 其实就是ApplicationContext的顶级类,可以创建、获取Bean。
     BeanFactory是个Factory，也就是IOC容器或对象工厂，FactoryBean是个Bean

  FactoryBean 也是一个接口，但是他是一个Bean,实现三个接口 其中getObject需要返回一个对象。
    getObject这个对象可以是任意对象。
    实际上实现了 FactoryBean会 有两个Bean,一个是 实现了FactoryBean的对象,另外一个就是getObject()对象。
    获取 实际上实现了 FactoryBean 需要加&+方法名称的方式 例子: applicationContext.getBean("&testFactoryBean");
    获取 getObject() 则直接使用 applicationContext.getBean("testFactoryBean");

    为什么要这么用FactoryBean ? FactoryBean 有什么用?
      当我们使用第三方框讲比如 Mybatis、Dubbo、Hibernet的时候 
      加入 我们需要 使用 SqlSessionFactory,无论我们是使用xml,或者注解的方式都需要注入 这个SqlSessionFactory 的依赖关系。
      而且 这个 SqlSessionFactory 依赖关系非常复杂，属性非常多。甚至 依赖了第三方服务。 那么这个时候就不能在Spring 中解决
      这种依赖。那么这个时候该怎么办呢。 最好的方式就是Mybatis 自己把SqlSessoinFactory 直接做成一个Bean放到Spring 容器中。
      这个时候 FactoryBean就可以实现了。Mybatis就是用了SqlSessionFactoryBean来解决了这个问题。!!!!!!
    
      2. 当我们有一个非常复杂的依赖关系,在spring配置超级麻烦。而对方又只想着直接使用。
      那么这个时候就可以使用FactoryBean来解决这种复杂的依赖关系。一般常用于 第三方框架中。比如:mybatiys、Dubbo

   Spring的扩展点有哪些?
     Spring自己实现


     BeanPostProcess 是一个扩展接口,接口有两个 postProcessBeforeInitialization();在初始化之前执行。
     postProcessAfterInitialization()。在初始化之后执行。
    
     BeanFactoryPostProcess Spring扩展接口,实现





  Spring @AdviceController 原理

  Spring 自定义注解,如何使用 
     方法1
     1.通过实现 Spring接口BeanFactoryPostProcess 或者 ApplicationContextAware 获取SpringBeanDefinition
     2.通过BeanDefinition 获取注解，根据注解执行逻辑
     方法2 
     通过aop 获取方法中的注解。
     方法3
     通过Import获取





  lookup-method(@Lookup)  
    在Spring中多数的bean都是单例的，但是如果有一个单例bean需要引用一个prototype bean怎么处理了，不可能每次都需要查询加载bean吧。在这样的场景下lookup-method可以很好的解决。
  replace-method

  Spring 注册BeanDefinitaion 源码
    DefaultListableBeanFactory.registerBeanDefinition(String beanName, BeanDefinition beanDefinition);
      把BeanDefinition 放入 beanDefinitionMap 中。

#####   Spring IOC 的理解:

​    Spring 容器会根据 Xml,或注解的配置实例话Bean对象，然后根据配置关系对Bean之间的描述进行依赖注入。解耦: 某个Service 被修改实现直接new就可以。
​    底层实现原理 反射 和 Cglib

  Spring 生成Bean 
     beanInstance = getInstantiationStrategy();
     根据 InstantiationStrategy 选择是使用 SimpleInstantiationStrategy ,还是 CglibSubclassingInstantiationStrategy
  Spring 获取Bean源码
     AbstractBeanFactory.getBean().doGetBean
       mbd.isSingleton()
         createBean(beanName, mbd, args)
           AbstractAutowireCapableBeanFactory.createBean()
             doCreateBean
               createBeanInstance()
                 instantiateBean()
                   getInstantiationStrategy().instantiate(mbd, beanName, parent)
                     InstantiationStrategy 有两个实现 SimpleInstantiationStrategy 和 CglibSubclassingInstantiationStrategy
                       会调用 SimpleInstantiationStrategy 根据 bd.getMethodOverrides().isEmpty() 判断 条件为true
                       使用 反射获取构造方法生成对象。BeanUtils.instantiateClass(constructorToUse);
                       默认使用 CglibSubclassingInstantiationStrategy 生成Bean的子类。

  Spring 如何保证Bean的实例是单例模式的?
    Spring框架对单例的支持是采用单例注册表的方式进行实现的AbstractBeanFactory.getBean()。


  AOP 理解: 面向切面编程,更加关注业务逻辑实现。避免写重复代码，与业务无关 比如 事物、日志、鉴权 都可以统一实现。

#####   AOP原理

​    由AopProxyFactory根据AdvisedSuport对象配置来决定,如果被代理目标是接口则使用JdkProxy来实现,否则使用Cglib(字节码生成子类)库实现。
​    源码: DefaultAopProxyFactory  

  Spring AOP 与 AspectJ 的区别与联系  
    AspectJ: AspectJ是一个面向切面的框架，它扩展了Java语言。AspectJ定义了AOP语法，所以它有一个专门的编译器用来生成遵守Java字节编码规范的Class文件。
    源码实现:
      当我们在一个类上开启AOP注解的时候,@EnableAspctJAutoProxy,Spring会向BeanPostProcess注册一个
    AnnotationAwareAspectJAutoProxyCreator 这个类实现了BeanPostProcess ->DefaultAopProxyFactory。
    DefaultAopProxyFactory 会根据判断来决定是使用JDK 还是 CgLib。完成了aop

  IOC(Inversion of Control)原理:
    Spring 启动时读取Bean配置信息 XML(Bean) @Configuration @AutoWired,在容器中生成一份 Bean定义注册表,根据注册表去实例化Bean。
    并装配bean之间的依赖关系。将Bean放入到缓冲池中。通过反射机制实例化Bean。
    DI(Dependency Injection): 依赖注入,对象所依赖的类不是自己寻找,是在容器实例化对象的时候主动注入。
  Spring Bean生命周期:
     1.实例化Bean设置Bean属性
     2.实现各种Aware 接口 BeanNameAware 可以获取Bean在实例中的名字
     3.BeanPostProcess 前置初始化方法
     4.initializingBean Bean实例化后后置处理
     5.调用 Bean init 方法 做初始化工作
     6.BeanPostProcess 后置初始化方法
     7.Bean 实例化完成
     如果Bean 实现了DisposableBean 接口 调用destory方法
     如果配置了 destry-method 则会调用其配置的销毁方法

  Spring 对象注入的源码分析
    BeanDefinitaion 接口 Bean的基本定义
      AbstractBeanDefinitaion 实现了 BeanDefinitaion接口。
    当 BeanDefinitionBuilder 完成后，会调用 DefaultListableBeanFactory.registerBeanDefinitaion 
    放入 beanDefinitionMap(ConcurrentHashMap) 完成注入对象。
  Spring 事物 隔离级别、传播特性实现原理
    https://blog.csdn.net/convict_eva/article/details/83544328
    https://blog.csdn.net/jyxmust/article/details/81260007
    https://www.liangzl.com/get-article-detail-16667.html
    @Transactional 注意事项 
      1.方法必须是 必须是 public 方法。
      2.默认情况下 事物抛出继承自 RuntimeException 的异常）或者 Error，则 Spring 将回滚事务；除此之外，Spring 不会回滚事务。你如果想要在特定的异常回滚可以考虑rollbackFor()等属性
      3.不建议用在处理时间过长的事务。因为，它会一直持有数据库线程池的连接，造成不能及时返回。就是尽量是的事务的处理时间短。
    读取 @Transaction 注解获取属性值,默认值。然后开启事物
    读取 隔离级别 判断隔离当前隔离级别事物,执行后续操作。

  BeanFactory 与 FactoryBean 有什么区别?
    FactoryBean

  BeanFactory 与 ApplicationContext有什么关系?
     BeanDefinition:
       保存了Bean的信息,Bean指向哪个类,是否单例,是否懒加载、依赖了哪些Bean
     ApplicationContext 间接继承了 BeanFactory
     BeanFactory 提供了简单的获取Bean 、是不是单例、获取Bean类型 、获取bean别名等。

     ApplicationContext:
       BeanFactory: 管理 装配Bean。
       ResourcePatternResolver: 加载资源文件。
       MessageSource: 国际化。
       ApplicationEventPublisher: 注册监听器,实现监听机制。
     AbstractBeanFactory: getBean 获取Bean的具体实现方法,根据Bean的定义 实例化方法. 单例 是否有依赖 等  

##### SpringMVC

  SpringMVC 流程:


   1、用户发送请求到前端控制器DispatcherServlet。
   2、前端控制器请求HandlerMapping查找Handler，可以根据xml配置、注解进行查找。
   3、HandlerMapping返回Handler（也就是我们常说的控制器，controller）。
   4、处理器适配器执行Handler。
   5、Handler返回ModelAndView，HandlerAdapter将它返回给DispatcherServlet。
   6、DispatcherServlet将ModelAndView传给ViewReslover视图解析器。
   7、ViewReslover解析后返回具体View。
   8、DispatcherServlet渲染View返回给用户。

  @Controller 和 @RestController 有什么不同?
    1.@RestControllrt相当于 @ResponBody + @Controller 的组合。
    2.@RestController 注解Controller 以后 InternalResourceViewResolver 将不起作用返回的就是 return 的内容。
    3.如果需要返回指定页面,需要用 @Controller + InternalResourceViewResolver 才能生效。

##### 设计模式

(https://blog.csdn.net/lj1314ailj/article/category/7491257):

  观察者模式
    定义对象间的一种一对多的依赖关系。当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。
    1.观察者模式实现了观察者和目标之间的抽象耦合
    2.观察者实现了动态联动
    3.观察者模式支持广播通讯
  经典实现:
    zookeeper
    dubbo  
  装饰器模式:
    装饰器模式又称为包装（Wrapper）模式。装饰器模式以多客户端透明的方式扩展对象的功能，是继承关系的一个替代方案。


  策略模式: 
     Spring 生成Bean 策略模式
     Spring BeanPostProcess 的实现类
  单例模式
  适配器模式
    将一个类的接口转换成客户希望的另一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。
  责任链模式


BIO NIO AIO
  BIO: bocking-io :阻塞io，JDK 1.4 之前的IO   
  NIO: non-bocking-io 非阻塞IO jdk 1.4 新特性。
  AIO: asyn-io 异步IO

##### MySql:


  如何保证DB数据一致性?
    通过并发控制,日志恢复技术避免这种情况的发生。

    并发控制:保证事务的隔离性、一致性
    日志恢复:保证了事务的一致性、原子性,和持久性。
    
    事务的原子性是通过undo log来实现的。
    事务的持久性是通过redo log实现的的。
    事务的隔离性是通过(读写锁 +MVCC)实现的。
    事务的一致性是通过 原子性、持久性、隔离性来实现的。
    
    在执行任何写操作，首先吧数据备份到一个地方（就是undo Log）然后进行写操作。如果出现了错误利用undo log恢复之前的状态。
    在执行任何写操作，首先把数据写到redo log ,直接调用fsync存盘。





RR隔离级别下read-view 不会刷新。
ACID:
    atomic :原子性,即作为最小执行单元不可再被分割。
    consistency: 一致性,即sql 入库前和入库后的操作是一致的。
    iostation: 隔离型,db对sql隔离级别 不同的隔离级别会带来不同的问题。
      read uncommitted: 未提交读,一个事物读到了另外一个事物中未提交的数据。
        脏读: 一个T读取到另一个T中未提交的数据。
      read committed: 已提交读,t2读取到了t1提交的数据。
        不可重复读: 一个T 多次读取数据不一致,因为另外一个T在做修改。 侧重于对同一数据的修改。
      repetable read: 可重复度,多次读取数据是一致的不会发生改变。
        幻读: 一个t 读取到了另外一个T中的插入或删除操作 。侧重于新增或删除
        避免: 
      serializable: 串行化,该级别不会产生上述问题，但是会发生表及锁。
    durability: 持久性,对数据的操作应该永久保存在DB中不会消失。

  死锁:
  Mysql索引失效: 
     1.索引无法存储null值

  聚集索引和非聚集索引
    聚集索引:

      1.属于InnoDB 
      2.按照B+Tree数的结构存放,子节点存放的就是数据.(如果没有主键,以唯一键作为索引,如果没有唯一键则默认生成隐藏主键)
      3.一张表只能有一个聚集索引
      4.普通索引指向聚集索引,普通索引先找到聚集索引,然后再次查询(回表)。
    
    非聚集索引:
    
      1.属于MyIsam。
      2.和普通索引没有什么区别
      3.存放的是地址。

  char和varchar的区别(https://www.cnblogs.com/webph/p/6679815.html)
     char 表示固定长度。
     varchar表示变长,长度不可变化。
     当所插入的字符串超出它们的长度时，视情况来处理，如果是严格模式，则会拒绝插入并提示错误信息，如果是宽松模式，则会截取然后插入。如果插入的字符串长度小于定义长度时，则会以不同的方式来处理，如char（10），表示存储的是10个字符，无论你插入的是多少，都是10个，如果少于10个，则用空格填满。而varchar（10），小于10个的话，则插入多少个字符就存多少个。

     char 最多能存放的字符个数 255，和编码无关。
     varchar 最多能存放 65532 个字符。VARCHAR 的最大有效长度由最大行大小和使用的字符集确定。


  为什么使用索引?

  什么是聚集索引?
    若主键被定义，主键就是聚集索引。
    若主键没有被定义，则唯一键作为索引。
    上述不满足 则隐式生成
    非主键索引会查找两次,一次查找id本身，然后在查找id对应的数据。
    优点: 
      B+树的节点中存储了表的行信息。根据聚集索引检索一次就可以获得主键对应的数据。

  非聚集索引
    先查询索引(主键),然后根据主键获取对应的信息。 

  


    可以提高查询性能,节省开销,提高效率。
  什么样的信息可以成为索引?
    主键、唯一、普通字段。
  索引的数据结构?
    B+Tree 、bitMap、hash


    B-Tree: 
    B 树也是有缺点的，因为每个节点都包含 key 值和 data 值，因此如果 data 比较大时，每一页存储的 key 会比较少；当数据比较多时，同样会有：“要经历多层节点才能查询在叶子节点的数据” 的问题。

  最左前缀?
    联合索引有最左前缀的概念. 
  InnoDB与MyISAM 关于锁方面的区别是什么?
    MyISAM 默认是表级锁,不支持行级锁。
      锁: 读写|写写 表数据互斥 读读不互斥。
      场景: 频繁执行全表count语句 | 查询远远高于写操作的表 | 没有事物的场景
  InnoDB 默认用的是行级锁,也支持表级锁。 
      锁: 在没有用到索引的情况下,也是使用了表级锁。
      场景: 数据写操作频繁 | 可靠性比较高,支持事物.    
  MVCC:


  Gap锁:
  当前读: select xx for update | update delete insert  即加了锁的语句 读取最新数据。
  快照读: 不加锁的非阻塞读。 select       
      
  Mysql 分表月份聚合查询



##### mybatis

  MapperRegistry 注册mappper 
  MapperProxyFactory  获取Mapper代理工厂
  mapperProxyFactory.newInstance(sqlSession);
    MapperProxy 实现了InvocationHandler接口 生成具体 Mapper代理对象 MapperProxy<T>(sqlSession, mapperInterface, methodCache)
      Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy); 生成具体Mapper 代理。

  你说你用过mybatis,那你知道Mapper接口的原理吗?
    如果回答得不错,并且提到动态代理这个关键词会继续往下问,那这个动态代理又是如何通过依赖注入到 Mapper 接口的呢?



##### zookeeper

https://www.cnblogs.com/zz-ksw/p/12786067.html
https://www.cnblogs.com/lanqiu5ge/p/9405601.html#_label14
https://blog.csdn.net/zpoison/article/details/80615468
https://www.cnblogs.com/goody9807/p/6535210.html
https://www.cnblogs.com/ASPNET2008/p/6421571.html



ZooKeeper并没有直接采用Paxos算法，而是采用一种被称为ZAB（ZooKeeper Atomic Broadcast）的一致性协议


  znode:不能用于存放大量的数据，每个节点的存放数据上限为1M
    PERSISTENT:
       持久化目录节点,客户端与zookeeper断开连接后，该节点依旧存在。
    PERSISTENT_SEQUENTIAL:
       持久化顺序编号目录节点,客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号
    EPHEMERAL:
      临时目录节点,客户端与zookeeper断开连接后，该节点被删除。
    EPHEMERAL_SEQUENTIAL:
      临时顺序编号目录节点,客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号。     



  myid:集群环境中 服务器数字唯一标示。
  zxid(zookeeper transaction id):有序性是zookeeper中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid（Zookeeper Transaction Id）

  Zab(zookeeper atomic broadcast)协议:
    原子广播协议,这个机制保证了各个Server之间的同步。
    选主(恢复模式):当服务启动或者在领导者崩溃后，Zab就进入了恢复模式。
    同步(广播模式):当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。
  zk分布式事务
    2PC两阶段提交
      1.客户端发起一个写请求。
      2.如果是 follower 节点接收到该请求，那么它会将该请求转发给 leader 节点处理。
      3.leader 会把这个请求转化成一个事务 Proposal（提议），并把这个 Proposal 分发给集群中的所有 Follower 节点（Observer不会被转发）。 
      4.Leader 节点需要等待所有 Follower 节点的反馈，一旦超过半数的 Follower 节点进行了正确的反馈（执行事务成功），那么 Leader 就会再次向所有的 Follower 节点发送 commit 消息，要求各个 follower 节点对前面的一个 Proposal 进行提交。
      5.leader 节点将最新数据同步给 observer 节点。
      6.follower 节点将结果返回给客户端。

  集群角色:
    leader:
      zk核心。 
      1.事物请求的唯一调度者，保证事物集群处理的顺序性。
      2.集群内个服务器的调度者。
    Follower:
      1.处理客户端非事物请求,转发事物请求给leader服务器
      2.参与事物请求 Proposal的投票。(需要半数以上服务器 通过才能通知 leadercommit 数据; Leader 发起的提案，要求 Follower 投票)  
      3.参与leader选举
    Observer:
      1.3.3.0版本以后引入的一个服务器角色，在不影响集群事务处理能力的基础上提升集群的非事务处理能力。
      2.处理客户端的非事务请求，转发事务请求给Leader服务器
      3.不参与任何形式的投票
  集群Server下的工作状态
    LOOKING:  寻找Leader状态。当服务器处于该状态时，它会认为当前集群中没有Leader，因此需要进入Leader选举状态。
    FOLLOWING: 跟随者状态。表明当前服务器角色是Follower。
    LEADING: 领导者状态。表明当前服务器角色是Leader。
    OBSERVING:观察者状态。表明当前服务器角色是Observer。

  ZK 为什么是奇数服务器 因为选举规则必须是 大于 半数。

  ZK leader选举:
    Leader选举是保证分布式数据一致性的关键所在。当Zookeeper集群中的一台服务器出现以下两种情况之一时，需要进入Leader选举。
    1.服务器初始化启动。
    2.服务器运行期间无法和Leader保持连接。
       1. 当集群感知到Leader挂了，那么所有Follower角色的服务器就转变状态从FOLLOWING变成LOOKING
       2. 每个服务器发出投票,因为第一轮都是投自己。
       3. 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行PK，PK规则如下
         优先检查ZXID。ZXID比较大的服务器优先作为Leader。
         如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。
       4. 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息。
       5. 改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING  
       6. 各个节点向leader节点注册自己信息，并开始同步数据。
   ZK 同步
     在master节点被确定之后，会进行同步数据。leader节点中维护了一个有序队列，保存了一个zixid 区间。minZxid - maxZxid
     minZxid: 从当前Zxid向前500个的zxid。
     maxZxid: leader节点的zxId

     当某个Flower 发送请求同步数据,如果Flower节点zxid 小于 Leader节点的minZxid,这个时候会进行SNAP全量同步
     当某个Flower 发送请求同步数据,如果Flower节点zxid 大于 Leader节点的maxZxid,这个时候会进行TRUNC同步,删除多余数据。
     当某个Flower 发送请求同步数据,如果Flower节点zxid 在 Leader节点 min-max 区间，这个时候会进行DIFF 差异化同步
    
     为什么会出现Flower节点大于 Leader节点这种情况? 
       当前leader节点正在处理一个写请求，包装了一个Proposal,并且把zxid。
       此时Leader突然宕机,zxid只存在了本地，其他Flower并没有收到zxid。
       此时集群中的机器已经选出了新的Leader,而刚才宕机的Leader节点重新加入集群成了Flower
       此时这个由宕机原因转化成Floer的节点 Zxid是最大的。这个时候就会出现Flower Zxid 大于 Leader节点的Zxid


     全量同步（SNAP同步）
     直接差异化同步（DIFF同步）
     仅回滚同步（TRUNC同步）
     先回滚再差异化同步（TRUNC+DIFF同步）

   ZK持久化方式:
     SNAPSHOT:对整个数据文件的存储,类似于redis RDB
     TXN-LOG: 记录当前事务请求 ,类似于 Redis AOF
     

   ZK 分布式锁 惊群效应 ?
   ZK 分布式锁 和Redis 分布式锁有什么不同 ?      

https://zhuanlan.zhihu.com/p/42056183



  算法:
    ZAB:
      Zab协议 的全称是 Zookeeper Atomic Broadcast （Zookeeper原子广播）。
      Zookeeper 是通过 Zab 协议来保证分布式事务的最终一致性。

    Paxos:paxos 算法用于构造一个分布式的一致性状态系统。
    Paxos算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。

  CAP:
    Zookeeper 保证的是CP 在leader选举集群是不可用状态，但对于服务发现而言，可用性比数据一致性更加重要 ，
    而 Eureka 设计则遵循AP原则 。

##### dubbo

  dubbo 模块分层:
    Service: 最上层服务,具体业务Service
    Config: 配置,各种 ReferenceConfig 、ServiceConfig
    Proxy: 代理层
    Registr: 注册中心
    Cluster: 集群、集群容错、负载均衡、路由
    Moniter: 监控
    Protocol: 协议。具体执行的调用的方式
    Exchange: 数据(信息)交换层 架起 C/S 管道进行通讯。
    Transport: 传输层，传输数据 netty 具体工作在这一层。
    Serialize: 序列化,具体执行序列化。

  dubbo为什么高性能?
     因为dubbo默认采用NIO socket 通讯,即采用了默认的TCP 方式进行通信,相较于http,TCP 只需要建立三次握手后就可以交互,不需要额外操作。另外TCP基于
     长链接的方式进行通讯,即相较于http不会每次请求结束后会关闭连接。其次 dubbo 采用了 高性能的序列化的方式对消息体编码/解码。高性能的原因基本基于
     以上两点。 1.采用TCP原生soket 方式通讯。 2. 采用高性能序列化工具编解码,减少压缩数据包大小。
  dubbo 协议:
    dubbo: 默认协议,其实是使用了netty 即NIO TCP socket 的通讯方式。
    http: 采用http方式进行调用。
    rmi: 采用RMI 方式进行调用。 
  dubbo原理:
     通过RPC(Remote Producer Call) 在consumer端生成代理 对象封装 请求方法、请求参数、 请求地址、端口等信息通过序列化  以NIO或Http 方式放松给
     provider . provider 接收消息 进行反序列化然后通过代理Or反射的形式调用本地方法,然后进行返回。
     1.服务消费者(client)调用本地调用方式调用服务
     2.client stub(客户端代理) 接收调用后负责将方法、参数等组装成能够进行网络传输的消息体。
     3.client stub(客户端代理) 找到服务地址,并将消息发送至服务端。
     4.server stub(服务端代理) 收到消息后进行解码。
     5.server stub(服务端代理) 根据解码结果调用本地服务。
     6.本地服务执行结果并返回给 server stub(服务端代理)
     7.server stub(服务端代理) 将返回结果打包成消息并发送至消费方。
     8.服务消费方得到最终结果。
     其中 RPC 框架会隐藏 2-6部的细节。使得client像调用本地方法一样调用远程服务。
  dubbo启动流程:
    1.Spring容器启动,DubboBeanDefinition 进行解析标签,生成对应的config对象。如果是Service 则生成ServerBean
    2.ServiceBean 实现了InitializingBean,ApplicationContextAware, ApplicationListener, BeanNameAware等接口
    Exchangers.bind 启动dubbo服务.
  设计模式:
     观察者模式
       在dubbo provider服务启动时候要向注册中心注册自己的服务，在dubbo consumer向注册中心订阅服务时则是一种观察者模式，他开启了一个listener，注册中心会每 5 秒定时检查是否有服务更新，如果有更新，向该服务的提供者发送一个 notify 消息， provider 接受到 notify 消息后，即运行 NotifyListener 的 notify 方法，执行监听器方法。
  调用过程:
  javaSPI 有什么缺点?
    不支持IOC、AOP功能。
    不能以key-value的方式获取实现。不能单独获取对象。
  源码: 
    负载均衡源码
  dubbo SPI 机制
     SPI(Service Provider Interface) 即服务提供商接口
       用户可以自定义实现接口,比如，负载策略只有5种，我们可以自定义一种，然后实现dubbo的对应的负载接口即可使用。

     只要是dubbo里面标注了@SPI注解的接口，均对外扩展，例如扩展负载功能
       实现LoadBalance接口，重写负载算法。
       在resource路径下的META-INF下建dubbo文件夹，然后在这个路径下建接口的全路径名的文件com.alibaba.dubbo.rpc.cluster.LoadBalance，在文件里面以key=value的形式指定自定义的负载器即可。
    
     ExtensionLoader： 是整个SPI的核心，创建对应扩展接口的适配对象。


  dubbo 暴露服务的过程?
    1.暴露本地服务
    2.暴露远程服务
    3.启动netty
    4.链接zk
    5.监听zk
  dubbo 本地暴露和远程暴露?
    本地暴露是暴露在JVM中,不需要网络通信.
    远程暴露是将ip,端口等信息暴露给远程客户端,调用时需要网络通信.
  dubbo 负载均衡
    Random: 按权重随机，根据weight值（服务方设置）来随机。
    Roundrobin: 轮询访问。
    Leastactive: 谁最轻松，访问谁，慢的机器，收到的请求少。
    ConsistentHash：一致性Hash，相同参数的请求总是发到同一提供者，当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。

  dubbo 有哪些容错机制
    Failover:  失败自动切换，尝试其他服务器
    Failfast: 失败立即抛出异常
    Failsafe: 失败忽略异常
    Failback: 失败自动恢复，记录日志并定时重试
    Forking: 并行调用多个服务，一个成功立即返回
    Broadcast: 广播调用所有提供者，任意一个报错则报错



##### ElasticSearch


  什么是 LSM树 (Log Structured Merge Trees)?


  ES 写入数据过程?
    ES 写入文档首先写入IndexBuffer 中,过一段时间后会写到Segment中(IndexBuffer 写入Segment过程叫做 Refresh,Refresh不执行Fsync)
    Refresh 默认1秒发生一次,这就是为什么ES是进实时的。Refresh以后数据就可以被搜索了。
    如果有大量的系统写请求,就会产生很多的Segment。
    IndexBuffer 被占满时候,会触发refresh,默认是JVM 10%。

    为了保证数据不丢失,写入Segment的时候会写入transaction-log中。es refresh indexBuffer清空,transaction-log不会被清空。
    断电、宕机ES会丢失IndexBuffer的内容，其他的内容不会丢失。
    
    flush 
      调用refrsh ,调用Fsync,将缓存写入磁盘。清空transaction-log ,默认30min 一次。如果translog(512)满了也会触发 flush




  ES 写入内存数据会丢失吗?
    不会,ES写入内存的时候还会写入Translog。


  为什么搜索是 近实时 的？



  ElasticSearch 为什么那么快?
     Segment的不变性
       在底层采用了分段的存储模式，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能。
       不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。
       一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。
       其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。
       写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量。


    filter : 只过滤数据 不计算相关度评分
    query : 会计算 document 相对于搜索条件的的相关度评分,并且按照相关度 进行排序。
    如果只想要一些数据并不想计算相关度和 评分 就使用 filter
    
    filter 性能高于 query 
    1.因为不需要计算相关度和评分和排序
    2.filter 内部有缓存


doc Value(正排索引):
  建立到排索引的时候也会建立正排索引，正排索引用于排序。


到排索引为什么不可变化:
  因为lucen

  1.数据不变,可以一直保存在cache中。
  2.filter cache 一直驻留内存,提升数据性能。
  坏处: 每次都要重新建立索引


  写入 -> 
     1. buffer 
     2. commit point 
        3. index sgemnt 
     4.write Osche
     5.wriete osDisk

​        

​    





##### Apollo

  原理 : 

JDK 动态代理原理:

##### springBoot

  SpringBoot核心
    autoConfiguration 自动配置
    start Dependency 起步依赖
    CLI 命令行界面
    Actuator 监控
  自定义自动装配
    1.编写java config @Configuration
    2.添加条件 @Conditionl
    3.定位自动配置 MATA-INF/spring.factories

  自定义起步依赖
    1.autoconigure 模块包含自动配置代码
    2.starter模块,包含自动装配的依赖以及其他的依赖
    命名方式
      xxx-spring-boot-autoconfigure
      xxx-spring-boot-starter


  springBoot 启动流程
     SpringApplication.run()方法,返回ConfigurableApplicationContext。调用方法 createApplicationContext(); 创建一个
     ApplicationContext 会根据当前类型推断 当前应用环境 如果是
  SpringBoot 自动装配 Spring Boot 自动配置原理是什么？

     @EnableAutoConfiguration 
       AutoConfigurationSeletor
         加载 MATA-INFO/spring.factories

注解 @EnableAutoConfiguration, @Configuration, @ConditionalOnClass 就是自动配置的核心，
@EnableAutoConfiguration 给容器导入META-INF/spring.factories 里定义的自动配置类。    


  springBoot 自定义实现一个autoconfig



##### Kafka(分布式流处理平台):

  为什么要用kafka?与其他中间件有什么不同?有什么优点?
     1.kafka提供了发布订阅及topic支持。
     2.kafka吞吐量高,不保证消息有序。
  kafka 可以做什么?
    1.日志收集
    2.消息系统
    3.用户活动跟踪或运营指标监控
  kafka 为什么吞吐量这么大?
      1.日志顺序读写和快速检索 （顺序读写内存比较快,随机读写内存慢 MMP 内存文件映射）
      2.Partition机制
      3.批量发送接收及数据压缩机制
        没有sendfile 读取
          1.从内核空间读取文件到内核缓冲区
          2.通过上下文切换读取到用户缓冲区
          3.再次切换到内核读取到soket缓冲区
          4.用户通过网卡到soket缓冲区读取数据
      4.通过sendfile transfor to(操作系统地层替我们实现的  windows下没有实现)实现零拷贝原则 (1.从内核直接读取缓冲区 无需上下文切换,不到中间进程 2.直接到进程 )

  Kafka 如何保证顺序性?
    单个parition有序,(一般不会这么做)

​      








Apollo 配置中心:
   原理


springCloud
  eureke
  zuul
  config
  feign
  hystrix :
    服务降级: 降级就是备胎。。。

      什么时候触发降级:
        熔断器是否打开
        线程池、信号量已满
        业务逻辑异常
        业务逻辑超时
    
    隔离方式: 信号量 、线程池
    
    断路器:
      状态:
        熔断器开启(open): 所有请求都会进入fallback方法
        熔断器半开(half-open): 熔断器半开状态,间歇性5S让请求出发run方法。
        熔断器关闭(close): 正常处理业务
        默认情况下熔断器开启5秒后,进入半开启状态。
      熔断器核心指标:
        时间窗口: 指定的一段时间内
        请求总数阈值: 在指定时间的设置的值
        错误百分比阈值: 在指定的时间窗口错误达到一定比例
        计算规则 ： 时间窗口内 有桶位,每个桶位有请求记录 success 、failure、timeout、rejection 根据时间窗口进行汇总。
    
    业务异常如何保证服务不降级:
      ignoreExceptions 可以忽略我们自定义的业务异常。
    舱壁隔离(Bulkhead Pattern): 
    降级策略:
      FailFast 快速失败
      FailSilent 安静失败 配置一个降级函数 ，返回空值或Null
      StaticFallback: 配置降级函数返回缺省值。

##### MQ

  rabbitMQ:
    消息生产者投递到 虚拟主机(Virtual Host) 到达交换机(Exchange) 根据交换机(Exchange)类型Type 选择绑定的消息队列(Queue) 消费者监听消息队列获取消息。
  exchange: 交换机
     type:
       default: routingKey直接路由到相同的队列名称中。
       direct: 直连模式  消息投递到交换机exchange 直接投递到与RoutingKey名称相同的队列中。p2p 模式
       topic:  主题模式  消息投递到交换机exchange 根据routingKey 模糊匹配(#匹配一个或多个|*匹配一个)对应的队列。可以实现 pub/sub 模式
       fanout: 分裂模式  不处理路由键,只要简单的将队列(Queue)绑定到交换机(Exchange)上即可。简单高效的 pub/sub 模式 
       headers: 消息头模式
  JMS 和 AMQP 有什么不同 ?
    JMS: JMS 消息规范
    AMQP: 高级消息队列协议  AMQP 核心 Exchange（交换机） 
  高级特性(Advanced):

    消息确认(Confirm):
       消息投递到Broker后,会给我们一个应答。用来保证消息投递成功。
    消息限流:
      QOS    
    rabbitMQ 如何保证消息100% 投递
      消息入库,对消息打标,分布式调度读取DB状态,根据状态做重试。不适合高并发。 
      消息延迟投递,做二次检查,回调检查。       
    rabbitMq 如何保证消息投递顺序
    rabbitMQ 如何保证幂等性
      放入redis中,对比业务规则。
    rabbitMQ 死信队列 







##### K8S:

  Cluster: K8S 集群 有若干Node组成.
  Container: 容器，通常指docker等
  Pod: k8s 最小调度单元，一个pod内可以有1个或者多个容器。
  Node: 组成k8s集群
  Service: 应用Pods的访问点，屏蔽ip寻址负载均衡
  ReplicatSet: 创建管理Pod 发布无状态 应用
  Deployment: 管理Replicat,支持滚动等高级发布
  ConfigMap/Secrets: 应用配置/加密配置
  DemonSet: Node中的守护进程，用于监控守护做日志收集管理。有且只能有一个。
  StatefulSet: 有状态的应用发布、redis集群
  Job : 支持1次调度
  CronJob: 周期调度


  Volume: 可挂在的文件存储
  PersistentVolume:超大磁盘存储抽象
  PersistentVolumeClaims: 磁盘分配
  Lable: 给pod资源打标签、
  Selector: 根据标签查询定位
  Namespace : 逻辑隔离 、 实现多租户、环境隔离
  Rediness probe : 就绪探针
  Liveness probe : 存活探针









秒杀:

   解决方案:

     限流策略: 秒杀前先限流,同一个id如果请求次数超过一定的频次,会丢让秒杀请求在1分钟内丢弃。
    
     在Redis序列提前存储与秒杀数量一致的秒杀token。当有请求进来的时候向redis Set中写入用户id,
     这个set数量与秒杀数量一致。当set中的数量满的时候。 后续请求全部丢弃。
    
     此时从set中取出用户id,取出秒杀token。 
     入队 -> 扣库存

   如何防止用户在未开始前疯狂请求接口?
     真实接口，在开启秒杀后需要有请求令牌。如果没有请求令牌 && 服务器其实不匹配直接return
   用户如何获取令牌?
     在倒计时正式开始的时候,CND刷新JS 新增获取令牌接口。

   





如何解决幂等性问题?
   1.业务状态机
   2.分布式锁

JDK 动态代理 实现原理? 通过编译可以看出来是一个类 继承了 proxy,实现了原来的接口


Apoll 怎么实时推送的? 

hashMap 到底是怎么线程不安全的? 不安全 为什么线程不安全? size

ZK 因为网络抖动产生了暂时 中断会不会产生两个 ?脑裂问题 不会产生两个leader 节点 因为master节点必须是  > 半数投票才能选举











为什么要用ES ? 
ElasticSearch 为什么快
   Elasticsearch/Lucene 为了提升索引和搜索的效率，从上层到底层，使用了各种巧妙的数据结构和设计，靠优秀的理论加极致的优化，做到查询性能上的极致。

    两者对比
    对于倒排索引，要分两种情况：
    
    1、基于分词后的全文检索
    
    这种情况是es的强项，而对于mysql关系型数据库而言完全是灾难
    
    因为es分词后，每个字都可以利用FST高速找到倒排索引的位置，并迅速获取文档id列表
    
    但是对于mysql检索中间的词只能全表扫（如果不是搜头几个字符）
    
    2、精确检索
    这种情况我想两种相差不大，有些情况下mysql的可能会更快些
    如果mysql的非聚合索引用上了覆盖索引，无需回表，则速度可能更快
    es还是通过FST找到倒排索引的位置并获取文档id列表，再根据文档id获取文档并根据相关度算分进行排序，但es还有个杀手锏，即天然的分布式使得在大数据量面前可以通过分片降低每个分片的检索规模，并且可以并行检索提升效率
    
    用filter时更是可以直接跳过检索直接走缓存



你有什们问题要问我吗?
  1.我们针对新人会有业务知识培训吗
  2.我们有遇到过P0级故吗?  X
  3.对这个岗位的期待
  4.我们技术团队氛围好吗?
  5.我很想争取进贵公司，所以想更清楚公司对这份     -------   工作的期待与目标。
  6.这个职务是我一直以来很想做的理想工作，所以我想多了解，还有没有哪些条件     是我要先具备的
  7.我听之前的面试官讲到我们之前服务全部都已经容器话了，在容器化的过程中是否遇到过什么问题?



#### 关键点：

##### SpringCoud

###### Eureka

https://juejin.im/post/6844903481019465742#heading-5

- 理解Eureka结构图
- 服务注册、服务续约（30秒），核心源码位置initScheduleTask
- 服务下线、服务剔除（3个续约期，90秒）
- 自我保护（15分钟续约低于85%），注册列表不删除保证可用
- Eureka的AP和Zookeeper的CP对比

###### Ribbon

https://blog.csdn.net/qq_20597727/article/details/82860521

- Ribbon原理

  Rbbon的实现原理利用了RestTemplate的拦截器机制，在拦截器中实现Ribbon的负载均衡。`RestTemplate` 的父类 `InterceptingHttpAccessor` 有个属性`List<ClientHttpRequestInterceptor> interceptors`，Ribbon则是实现`LoadBalancerInterceptor`（拦截器）并通过SPI加载到`LoadBalancerAutoConfiguration`，从而将拦截器设置到定制化的`RestTemplate`属性中。通过`RestTemplate`的Http请求就会被拦截，通过`chooseServer`选择服务，并将请求封装成request，将响应结果封装成response返回给client

- 负载均衡算法：轮询（默认，10轮）、随机、重试（500ms）

- 自定义负载算法，实现IRule接口

###### Feign

- Feign原理：

  通过`@EnableFeignClients` 注解，启用`feign`客户端的扫描和注册机制，从而可以发现注解`@FeignClient`定义的`feign`客户端，并最终以`FeignClientFactoryBean`类型的bean注册到容器中。再通过`@Autowired`自动注入，这些`feign`客户端会以`ReflectiveFeign$FeignInvocationHandler`（dispatch`变量保存方法和方法处理器的key-value）动态代理的形式被注入到使用方。该`feign`客户端包含了对每个接口方法的处理器`MethodHandler`,接口缺省方法对应`DefaultMethodHandler`,服务功能端点方法对应`SynchronousMethodHandler`。

- Feign提供了默认的 SynchronousMethodHandler 实现类，提供了基本的远程URL的同步请求处理。

  1. 首先通 RequestTemplate 请求模板实例，生成远程URL请求实例 request；
  2. 然后用自己的 feign 客户端client成员，excecute(…) 执行请求，并且获取 response 响应；
  3. 对response 响应进行结果解码。

- Feign的client

  - Client.Default
  - ApacheHttpClient
  - OkHttpClient
  - LoadBalancerFeignClient ：Ribbon实现的负载均衡客户端

- Feign和OpenFeign

  OpenFeign是Spring Cloud 在Feign的基础上支持了Spring MVC的注解，如`@RequesMapping`等等

###### Hystrix

http://www.iocoder.cn/Spring-Cloud/Netflix-Hystrix/?self

- Hystrix重要特性

  FallBack 服务降级、断路器机制、资源隔离

- FallBack 服务降级

  @HystrixCommand(fallbackMethod = "") 指定fallback方法

- 断路器机制

  Hystrix 内置断路器 [HystrixCircuitBreaker](https://github.com/Netflix/Hystrix/blob/master/hystrix-core/src/main/java/com/netflix/hystrix/HystrixCircuitBreaker.java) 实现，close、open、half_open三种状态。

  

###### Zuul

https://blog.csdn.net/forezp/article/details/76211680

https://juejin.im/post/6844903783432978439

- Zuul原理

   整个请求的过程：

  1. 首先将请求给zuulservlet处理，zuulservlet中有一个zuulRunner对象，该对象中初始化了RequestContext：作为存储整个请求的一些数据，并被所有的zuulfilter共享
  2. zuulRunner中还有 FilterProcessor，FilterProcessor作为执行所有的zuulfilter的管理器。FilterProcessor从filterloader 中获取zuulfilter，而zuulfilter是被filterFileManager所加载，并支持groovy热加载，采用了轮询的方式热加载。
  3. 有了这些filter之后，zuulservelet首先执行的Pre类型的过滤器，再执行route类型的过滤器，最后执行的是post 类型的过滤器，如果在执行这些过滤器有错误的时候则会执行error类型的过滤器。
  4. 执行完这些过滤器，最终将请求的结果返回给客户端。

- 路由功能

  统一前缀、路由策略配置、服务名屏蔽、敏感请求头屏蔽

- 过滤功能

  - 过滤器Filter生命周期
    - **PRE：** 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。
    - **ROUTING：**这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用Apache HttpClient或Netfilx Ribbon请求微服务。
    - **POST：**这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。
    - **ERROR：**在其他阶段发生错误时执行该过滤器。 除了默认的过滤器类型，Zuul还允许我们创建自定义的过滤器类型。
  - 自定义Filter，继承ZuulFilter覆盖4个方法
  - 路由熔断、降级，继承FallbackProvider，实现降级fallBack

  - 限流

    - 限流算法-漏桶

      漏桶算法可以将系统处理请求限定到恒定的速率，当请求过载时，漏桶将直接溢出。漏桶算法假定了系统处理请求的速率是恒定的，但是在现实环境中，往往我们的系统处理请求的速率不是恒定的。漏桶算法无法解决系统突发流量的情况。

    - 限流算法-令牌桶

    - RateLimiter基于令牌桶算法，可以有效限定单个JVM实例上某个接口的流量。

  - 灰度发布

  - 权限控制

