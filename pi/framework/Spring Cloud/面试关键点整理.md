#### 关键点：

##### Spring

- Controller 和 RestController

- IOC

- AOP

- ApplicationContext

  - 准备更新上下文
  - 初始化BeanFactory
  - 准备BeanFactory
  - 注册激活BeanFactoryPostProcessor
  - 注册BeanPostProcessor
  - 处理国际消息
  - 初始化时间广播
  - 注册监听
  - 初始化所有singleton bean
  - 结束初始化

- Spring Bean

  - 作用域

  - 生命周期

    实例化Bean --> 设置属性 --> 检查Aware接口设置相关依赖 --> BeanPostProcessor前置处理 --> 检查是否InitializingBean，决定是否调用afterPropertiesSet --> 检查是否配置init-method --> BeanPostProcessor后置处理 --> 注册必要的Destruction回调接口 --> 是否实现DeposableBean接口 --> 是否配置destroy-method

- 设计模式

  工厂模式、代理模式、单例模式、模版模式、适配器模式、装饰器模式、观察者模式。。。

- Spring事务

  - 隔离级别

  - 传播特性

    - PROPAGATION_REQUIRED —— 支持当前事务，如果当前没有事务，则新建一个事务，这是最常见的选择，也是 Spring 默认的一个事务传播属性。
    - PROPAGATION_SUPPORTS —— 支持当前事务，如果当前没有事务，则以非事务方式执行。
    - PROPAGATION_MANDATORY —— 支持当前事务，如果当前没有事务，则抛出异常。
    - PROPAGATION_REQUIRES_NEW —— 新建事务，如果当前存在事务，把当前事务挂起。
    - PROPAGATION_NOT_SUPPORTED —— 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
    - PROPAGATION_NEVER —— 以非事务方式执行，如果当前存在事务，则抛出异常。
    - PROPAGATION_NESTED —— Nested的事务和它的**父事务**是相依的，它的提交是要等和它的父事务一块提交的

  - 实现原理

    `initializeBean`方法入口：获取事务增强，创建代理。而后@Transaction方法调用时，执行before、after增强，创建、提交事务。

    PlatformTransactionManager

    TransactionDefinition

    TransactionStatus

    TransactionInterceptor # invoke 

- Spring循环依赖

  - 构造器依赖，直接异常

  - set 循环依赖

    singletonFactories ： 进入实例化阶段的单例对象工厂的cache （三级缓存）

    earlySingletonObjects ：完成实例化但是尚未初始化的，提前暴光的单例对象的Cache （二级缓存）

    singletonObjects：完成初始化的单例对象的cache（一级缓存）

##### SpringMVC

1. 客户端（浏览器）发送请求，直接请求到 `DispatcherServlet`。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。
3. 解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由 `HandlerAdapter` 适配器处理。
4. `HandlerAdapter` 会根据 `Handler `来调用真正的处理器来处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回一个 `ModelAndView` 对象，`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
6. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
7. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
8. 把 `View` 返回给请求者（浏览器）

##### SpringBoot

- @SpringBootApplication

  - @Configuration 

    实际为@SpringBootConfiguration，作为配置类Bean

  - @EnableAutoConfiguration 

    SpringBoot自动配置机制，通过import `AutoConfigurationImportSelector`的selectImports 方法读取 spring.factories 并SpringFactoriesLoader进行SPI拓展，实现自动配置机制

  - @ComponetScan 

    扫描包路径并加载符合条件的组件或bean定义

- SpringApplication

  Spring应用创建并初始化Spring上下文，run()方法默认返回一个ConfigurableApplicationContext对象，底层其实就是new了一个SpringApplication的对象，并执行run()方法。

  - SpringApplication的创建
    - 设置web 环境类型
    - SpringFactoriesLoader 加载 ApplicationContextInitializer
    - SpringFactoriesLoader 加载 ApplicationListener
  - run 方法执行
    -  初始化监听器
    - 发布ApplicationStartedEvent事件
    - 装配参数和环境
    - 打印启动的Banner
    - 根据web环境创建ApplicationContext（serverlet、 reactive），默认AnnotationConfigApplicationContext
    - prepareContext 刷新前操作：装配环境变量，发布PreparedEvent事件
    - 调用ApplicationContext的refresh()方法
    - refreshContext 刷新前操作：发布ReadyEvent事件等

##### SpringCoud

###### Eureka

https://juejin.im/post/6844903481019465742#heading-5

- 理解Eureka结构图
- 服务注册、服务续约（30秒），核心源码位置initScheduleTask
- 服务下线、服务剔除（3个续约期，90秒）
- 自我保护（15分钟续约低于85%），注册列表不删除保证可用
- Eureka的AP和Zookeeper的CP对比

###### Ribbon

https://blog.csdn.net/qq_20597727/article/details/82860521

- Ribbon原理

  Rbbon的实现原理利用了RestTemplate的拦截器机制，在拦截器中实现Ribbon的负载均衡。`RestTemplate` 的父类 `InterceptingHttpAccessor` 有个属性`List<ClientHttpRequestInterceptor> interceptors`，Ribbon则是实现`LoadBalancerInterceptor`（拦截器）并通过SPI加载到`LoadBalancerAutoConfiguration`，从而将拦截器设置到定制化的`RestTemplate`属性中。通过`RestTemplate`的Http请求就会被拦截，通过`chooseServer`选择服务，并将请求封装成request，将响应结果封装成response返回给client

- 负载均衡算法：轮询（默认，10轮）、随机、重试（500ms）

- 自定义负载算法，实现IRule接口

###### Feign

- Feign原理：

  通过`@EnableFeignClients` 注解，启用`feign`客户端的扫描和注册机制，从而可以发现注解`@FeignClient`定义的`feign`客户端，并最终以`FeignClientFactoryBean`类型的bean注册到容器中。再通过`@Autowired`自动注入，这些`feign`客户端会以`ReflectiveFeign$FeignInvocationHandler`（dispatch`变量保存方法和方法处理器的key-value）动态代理的形式被注入到使用方。该`feign`客户端包含了对每个接口方法的处理器`MethodHandler`,接口缺省方法对应`DefaultMethodHandler`,服务功能端点方法对应`SynchronousMethodHandler`。

- Feign提供了默认的 SynchronousMethodHandler 实现类，提供了基本的远程URL的同步请求处理。

  1. 首先通 RequestTemplate 请求模板实例，生成远程URL请求实例 request；
  2. 然后用自己的 feign 客户端client成员，excecute(…) 执行请求，并且获取 response 响应；
  3. 对response 响应进行结果解码。

- Feign的client

  - Client.Default
  - ApacheHttpClient
  - OkHttpClient
  - LoadBalancerFeignClient ：Ribbon实现的负载均衡客户端

- Feign和OpenFeign

  OpenFeign是Spring Cloud 在Feign的基础上支持了Spring MVC的注解，如`@RequesMapping`等等

###### Hystrix

http://www.iocoder.cn/Spring-Cloud/Netflix-Hystrix/?self

- 入门使用

  - 引入Hystrix的pom依赖
  - @EnableCircuitBreaker申明开启断路器
  - @HystrixCommand 注解方法上，属性：
    - fallbackMethod，fallback 服务降级的处理方法，处理相应的异常
    - ignoreExceptions，指定忽略指定的异常
    - commandKey，Hystrix Command 命令**键**，默认方法名
    - groupKey，据不同的分组来统计命令的统计、告警、仪表盘信息
    - threadPoolKey，用于划分不同的线程池，进行资源隔离
  - @CacheResult 注解，添加在方法上，声明将方法的执行结果进行缓存，并后续从缓存中获取结果
    - `cacheKeyMethod` 属性：设置**缓存键**的生成方法
  - @CacheRemove 注解，添加在方法上，声明移除指定 Hystrix Command 生成的缓存。
    - `commandKey` 属性：设置 Hystrix Command **键**。
    - `cacheKeyMethod` 属性：设置**缓存键**的生成方法。

- Hystrix重要特性

  FallBack 服务降级、断路器机制、资源隔离

- FallBack 服务降级

  @HystrixCommand(fallbackMethod = "") 指定fallback方法

- 断路器机制

  Hystrix 内置断路器 [HystrixCircuitBreaker](https://github.com/Netflix/Hystrix/blob/master/hystrix-core/src/main/java/com/netflix/hystrix/HystrixCircuitBreaker.java) 实现，close、open、half_open三种状态。

  1. 初始时，断路器处于 `CLOSED`状态，链路处于**健康**状态。当满足如下条件，断路器从 `CLOSED` 变成 `OPEN` 状态：
   1. 周期内（10000ms），总请求数超过一定量（20次）
     2. 错误请求比例（50%）
  2. 断路器处于 `OPEN`状态，命令执行时，若当前时间超过断路器**开启**时间一定时间( 5000 ms` )，断路器变成 `HALF_OPEN` 状态，**尝试**调用**正常**逻辑，根据执行是否成功，**打开或关闭**熔断器
  
- 资源隔离 ExecutionIsolationStrategy

  Hystrix 使用了“**舱壁隔离模式**”来隔离和限制各个请求，从而实现资源的隔离。Hystrix 通过**线程池**和**信号量（[Semaphore](https://github.com/openjdk-mirror/jdk7u-jdk/blob/master/src/share/classes/java/util/concurrent/Semaphore.java)）** 两种模式来实现隔离。

  - 线程池模式（默认）

    针对调用的每一个服务，我们给其**单独**分配一个线程池。

  - 信号量模式

    使用线程池模式来隔离时，需要进行上下文的切换，带来一定的性能损耗。因此，如果对性能有较高要求，且能够接受信号量模式不支持**超时**的情况，可以考虑采用信号量模式。

###### Zuul

https://blog.csdn.net/forezp/article/details/76211680

https://juejin.im/post/6844903783432978439

- Zuul原理

   整个请求的过程：

  1. 首先将请求给zuulservlet处理，zuulservlet中有一个zuulRunner对象，该对象中初始化了RequestContext：作为存储整个请求的一些数据，并被所有的zuulfilter共享
  2. zuulRunner中还有 FilterProcessor，FilterProcessor作为执行所有的zuulfilter的管理器。FilterProcessor从filterloader 中获取zuulfilter，而zuulfilter是被filterFileManager所加载，并支持groovy热加载，采用了轮询的方式热加载。
  3. 有了这些filter之后，zuulservelet首先执行的Pre类型的过滤器，再执行route类型的过滤器，最后执行的是post 类型的过滤器，如果在执行这些过滤器有错误的时候则会执行error类型的过滤器。
  4. 执行完这些过滤器，最终将请求的结果返回给客户端。

- 路由功能

  统一前缀、路由策略配置、服务名屏蔽、敏感请求头屏蔽

- 过滤功能

  - 过滤器Filter生命周期
    - **PRE：** 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。
    - **ROUTING：**这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用Apache HttpClient或Netfilx Ribbon请求微服务。
    - **POST：**这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。
    - **ERROR：**在其他阶段发生错误时执行该过滤器。 除了默认的过滤器类型，Zuul还允许我们创建自定义的过滤器类型。
    
  - 自定义Filter，继承ZuulFilter覆盖4个方法

  - 路由熔断、降级，继承FallbackProvider，实现降级fallBack

  - 限流

    - 限流算法-漏桶

      漏桶算法可以将系统处理请求限定到恒定的速率，当请求过载时，漏桶将直接溢出。漏桶算法假定了系统处理请求的速率是恒定的，但是在现实环境中，往往我们的系统处理请求的速率不是恒定的。漏桶算法无法解决系统突发流量的情况。

    - 限流算法-令牌桶

    - RateLimiter基于令牌桶算法，可以有效限定单个JVM实例上某个接口的流量。

  - 灰度发布
  
  - 权限控制

######  Config

`Spring Cloud Config` 就是能将各个 应用/系统/模块 的配置文件存放到 **统一的地方然后进行管理**(Git 或者 SVN)

使用 `Bus` 消息总线 + `Spring Cloud Config` 进行配置的动态刷新。

###### Bus

`Spring Cloud Bus` 的作用就是**管理和广播分布式系统中的消息**，也就是消息引擎系统中的广播模式。

##### 框架二次开发

###### Spring

- InitializingBean、DisposableBean
- BeanFactoryPostProcessor、BeanPostProcessor ： dubbo 注册和引用的过程
- Aware接口
- FactoryBean ：dubbo的ReferenceConfig、ServiceConfig、还有Feign的`FeignClientFactoryBean`

###### SpringBoot

​	可以说dubbo-starter ，解释下原理，顺便引出dubbo源码

##### Apollo

框架、原理

- 核心模块
  - ConfigService：微服务，提供配置获取、推送接口，服务于 client
  - AdminService：微服务，提供配置管理、配置修改接口，服务于Portal
  - Client
    - 为应用获取配置，支持实时更新
    - 通过MetaServer获取ConfigService服务列表
    - 使用客服端负载SLB方式调用ConfigService
  - Portal
    - 配置管理界面
    - 通过MetaServer获取AdminService服务列表
    - 使用客服端负载SLB方式调用AdminService
  - Eureka
    - 用于服务发现和注册
    - Config/AdminService注册实例并定期报心跳
    - 和ConfigService住在一起部署
  - MetaServer
    - Portal通过域名访问MetaServer获取AdminService的地址列表
    - Client通过域名访问MetaServer获取ConfigService的地址列表
    - 相当于一个Eureka Proxy
    - 逻辑角色，和ConfigService住在一起部署
  - NginxLB
    - 和域名系统配合，协助Portal访问MetaServer获取AdminService地址列表
    - 和域名系统配合，协助Client访问MetaServer获取ConfigService地址列表
    - 和域名系统配合，协助用户访问Portal进行配置管理



介绍：

- **统一管理不同环境、不同集群的配置**
  - Apollo提供了一个统一界面集中式管理不同环境（environment）、不同集群（cluster）、不同命名空间（namespace）的配置。
  - 同一份代码部署在不同的集群，可以有不同的配置，比如zk的地址等
  - 通过命名空间（namespace）可以很方便的支持多个不同应用共享同一份配置，同时还允许应用对共享的配置进行覆盖
  - 配置界面支持多语言（中文，English）
- **配置修改实时生效（热发布）**
  - 用户在Apollo修改完配置并发布后，客户端能实时（1秒）接收到最新的配置，并通知到应用程序。
- **版本发布管理**
  - 所有的配置发布都有版本概念，从而可以方便的支持配置的回滚。
- **灰度发布**
  - 支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例。
- **权限管理、发布审核、操作审计**
  - 应用和配置的管理都有完善的权限管理机制，对配置的管理还分为了编辑和发布两个环节，从而减少人为的错误。
  - 所有的操作都有审计日志，可以方便的追踪问题。

##### Dubbo

###### dubbo-stater

- 读取yml文件“spring.dubbo”的配置，获取DubboProperties（包括scan、ApplicationConfig、RegistryConfig、ProtocolConfig信息）注入到Spring容器中。
- 实现ApplicationContextInitializer初始化类，注入AnnotationBean（继承BeanFactoryPostProcessor、BeanPostProcessor等）到Spring容器中

注意：注解引用dubbo包是基于onApplicationEvent事件机制触发的

###### AnnotationBean

- 实现BeanFactoryPostProcessor

  初始化scanner、添加filter、扫描packages

- 实现BeanPostProcessor

  - postProcessBeforeInitialization

    处理Reference注解，通过refer方法注入Dubbo服务实例到容器中

  - postProcessAfterInitialization

    处理Service注解，接口注册到DU奔波的注册中心

    - 创建ServiceConfig，设置属性值
    - loadRegistries 获取要注册的Urls

    - 暴露核心业务流程：doExportUrlsFor1Protocol方法

###### 服务暴露过程

![](/Users/see-bruin/IdeaProjects/bruin/pi/framework/Dubbo/images/服务暴露过程.jpg)

暴露核心业务流程，doExportUrlsFor1Protocol方法：dubbo通过URL串联整个过程，第一步检查参数，组装 URL。第二部分是导出服务，包含导出服务到本地 (JVM)，和导出服务到远程两个过程。第三部分是向注册中心注册服务，用于服务发现。

- 本地暴露：暴露在JVM中,不需要网络通信

  - 获取Invoker（`AbstractProxyFactory#getInvoke`r）

    JavassistProxyFactory（默认）、JdkProxyFactory继承AbstractProxyFactory重写了getInvoker方法。通过getInvoke方法使用ref生成一个Invoker实例，完成Invoker的转化。

  - Invoker 转换成Exporter（`Protocol#export`）

    本地暴露比较简单，创建InjvmExporter,不需要网络通信

  - 缓存exporter

- 远程暴露：将ip,端口等信息暴露给远程客户端,调用时需要网络通信

  导出服务到远程的过程含了服务导出与服务注册两个过程。

  - 调用 doLocalExport **导出服务**

    - DubboExporter创建和缓存

    - openServer 方法

      - createServer

        第一是检测是否存在 server 参数所代表的 Transporter 拓展，不存在则抛出异常。

        第二是创建服务器实例。

        第三是检测是否支持 client 参数所表示的 Transporter 拓展，不存在也是抛出异常

      - ExchangeServer 的 bind 方法

        逻辑较多，关注Transporters 的 bind 方法

      - getTransporter() 方法获取的 Transporter

        运行时动态创建的，类名为 TransporterAdaptive，也就是自适应拓展类。TransporterAdaptive 会在运行时根据传入的 URL 参数决定加载什么类型的 Transporter，默认为 NettyTransporter。

      - Transporters 的 bind 方法

        就是 NettyServer 创建的过程

  - 向注册中心**注册服务**

    - 获取/创建注册中心实例

      getRegistry 方法先访问缓存，缓存未命中则调用 createRegistry 创建 Registry，然后写入缓存。这里的 createRegistry 是一个模板方法，由具体的子类实现。 以 Zookeeper 注册中心为例基于Curator 框架CuratorZookeeperTransporter创建zk 客户端

    - 服务注册

      以 Zookeeper 为例，所谓的服务注册，本质上是将服务配置数据写入到 Zookeeper 的某个路径的节点下。doRegister 方法是一个模板方法，因此我们到 FailbackRegistry 子类 ZookeeperRegistry 中进行分析。

###### 服务引用

![](/Users/see-bruin/IdeaProjects/bruin/pi/framework/Dubbo/images/服务引用过程.jpg)

AnnotationBean的 refer方法：构建ReferenceConfig，调用ReferenceConfig # init方法。接着头站Protocol的refer方法生成Invoker（服务消费关键），Invoker通过ProxyFactory转换成客户调用的ref（实际是个代理）

- ReferenceConfig # init
  - 检测 ConsumerConfig 实例， 读取配置文件填充 ConsumerConfig
  - 检测几个核心配置类是否为空，为空则尝试从其他配置类中获取
  - 析服务消费者 ip，以及调用 createProxy 创建代理对象
- 生成Invoker
  - 判断url 配置被指定，根据 url 的协议、scope 以及 injvm 等参数检测是否本地引用
  - 本地引用（InjvmProtocol # refer 生成Invoker）
  - Protocol 自适应拓展类构建 Invoker
  - Cluster 合并多个 Invoker，最后调用 ProxyFactory 生成代理类

###### 服务字典Directory

服务目录中存储了一些和服务提供者有关的信息，通过服务目录，服务消费者可获取到服务提供者的信息，比如 ip、端口、服务协议等。服务目录目前内置的实现有两个，分别为 **StaticDirectory** 和 **RegistryDirectory**，它们均是 AbstractDirectory 的子类。

- StaticDirectory

  静态服务目录，顾名思义，它内部存放的 Invoker 是不会变动的。所以，理论上它和不可变 List 的功能很相似。

- RegistryDirectory

  是一种动态服务目录，实现了 NotifyListener 接口。当注册中心服务配置发生变化后，RegistryDirectory 可收到与当前服务相关的变化。收到变更通知后，RegistryDirectory 可根据配置变更信息刷新 Invoker 列表

###### 路由Router

服务目录在刷新 Invoker 列表的过程中，会通过 Router 进行服务路由，筛选出符合路由规则的服务提供者。**ConditionRouter** 的 route 方法

- ConditionRouter
- ScriptRouter

###### 负载均衡

​	负载均衡实现类均继承自 AbstractLoadBalance，该类实现了 LoadBalance 接口

- 基于权重随机算法的 RandomLoadBalance
- 基于最少活跃调用数算法的 LeastActiveLoadBalance
- 基于 hash 一致性的 ConsistentHashLoadBalance
- 基于加权轮询算法的 RoundRobinLoadBalance

###### 集群Cluster

Dubbo 定义了集群接口 Cluster 以及 Cluster Invoker。集群 Cluster 用途是将多个服务提供者合并为一个 Cluster Invoker，并将这个 Invoker 暴露给服务消费者。这样一来，服务消费者只需通过这个 Invoker 进行远程调用即可，至于具体调用哪个服务提供者，以及调用失败后如何处理等问题，现在都交给集群模块去处理。集群模块是服务提供者和服务消费者的中间层，为服务消费者屏蔽了服务提供者的情况，这样服务消费者就可以专心处理远程调用相关事宜。

- Failover Cluster - 失败自动切换
- Failfast Cluster - 快速失败
- Failsafe Cluster - 失败安全
- Failback Cluster - 失败自动恢复
- Forking Cluster - 并行调用多个服务提供者

###### 集群工作过程

![](/Users/see-bruin/IdeaProjects/bruin/pi/framework/Dubbo/images/集群工作过程.jpg)

集群容错的所有组件：包含 Cluster、Cluster Invoker、Directory、Router 和 LoadBalance 等。

- 第一个阶段是在服务消费者初始化期间，集群 Cluster 实现类为服务消费者创建 Cluster Invoker 实例，即上图中的 merge 操作。
- 第二个阶段是在服务消费者进行远程调用时。以 FailoverClusterInvoker 为例
  - 该类型 Cluster Invoker 首先会调用 Directory 的 list 方法列举 Invoker 列表 
  - 当 FailoverClusterInvoker 拿到 Directory 返回的 Invoker 列表后
  - 通过 LoadBalance 从 Invoker 列表中选择一个 Invoker。
  - 最后 FailoverClusterInvoker 会将参数传给 LoadBalance 选择出的 Invoker 实例的 invoke 方法，进行真正的远程调用。

###### 服务调用

![](/Users/see-bruin/IdeaProjects/bruin/pi/framework/Dubbo/images/服务调用过程.jpg)

首先服务消费者通过代理对象 Proxy 发起远程调用，接着通过网络客户端 Client 将编码后的请求发送给服务提供方的网络层上，也就是 Server。Server 在收到请求后，首先要做的事情是对数据包进行解码。然后将解码后的请求发送至分发器 Dispatcher，再由分发器将请求派发到指定的线程池上，最后由线程池调用具体的服务。

- 同步和异步（有无返回值）调用

  InvokerInvocationHandler # invoke --> 

  AbstractInvoker # invoke -->

  **FailoverClusterInvoker # doInvoke**（就到了上面集群工作的过程，获取Invoker列表，route后，在负载均衡）

- 服务消费方发送请求

  - 发送请求

    经过多次ReferenceCountExchangeClient调用后，才将请求数据送至 Netty NioClientSocketChannel。这样做的原因是通过 Exchange 层为框架引入 Request 和 Response 语义.

  - 请求解码

    Dubbo数据包

- 服务提供方接受请求

  - 请求解码

    DecodeableRpcInvocation # decode

  - 调用服务

    NettyHandle r# messageReceived

    - Dispatcher 线程派发

    - 调用服务

      ChannelEventRunnable#run()  —> DecodeHandler#received(Channel, Object)    —> HeaderExchangeHandler#received(Channel, Object)    —> HeaderExchangeHandler#handleRequest(ExchangeChannel, Request)        —> **DubboProtocol.requestHandler**#reply(ExchangeChannel, Object)          —>

       Filter#invoke(Invoker, Invocation)            —> **AbstractProxyInvoker#invoke(Invocation)**              —> Wrapper0#invokeMethod(Object, String, Class[], Object[])                —> DemoServiceImpl#sayHello(String

- 服务提供方返回调用结果

- 服务消费方接收调用结果



##### Rbbitmq

https://zhuanlan.zhihu.com/p/63700605

https://blog.csdn.net/u013256816/article/details/60875666

###### 原理

- Message

  它由消息头和消息体组成

  - 消息体：不透明的
  - 消息头一系列的可选属性组成：routing-key（路由键）、priority（优先）、delivery-mode（持久化）

- Producer ：消息的生产者

- Exchange：交换器，接收生产者消息并将消息路由给queue

- Binding：绑定，用于消息队列和交换器之间的关联

- Queue：消息队列容器，用来保存消息直到发送给消费者。

- Connect：网络连接，比如一个TCP连接。

- Channel：多路复用连接中的双向数据流通道，避免重复connect

- Consumer：消息的消费者

- Virtual Host：虚拟主机（默认“/”），表示一批独立交换器、队列和相关对象

- Broker：消息队列服务器实体

###### Exchange type

- Direct exchange 直接转发路由

  通过消息中的routing key，与binding 中的binding-key 进行比对，若二者匹配，则将消息发送到这个消息队列。

- Fanout exchange 复制分发路由

  不需要routkey，当exchange收到消息后，将消息复制多份转发给与自己绑定的消息队列

- topic exchange 通配路由

  通配符模式，通配符匹配routing key和binding-key二者

###### 持久化

- 持久化类型：disk方式、RAM方式
  - Disk ，消息数据会被保存在.rdb的文件中（默认16M），超过新增一个文件，删除数据操作一定阀值触发文件合并
  - RAM方式，保存内部数据库表，不回保存消息、索引、状态等数据。启动时需要从集群中其他节点同步数据，所以集群中必须有一个节点时disk方式的持久化

- 持久化过程：

  - Buffer，先写Buffer（大小1M），满了再写入到磁盘
  - 固定刷盘时间：25ms,不管Buffer满不满都会写入到磁盘
  - 每次消息写入后，如果没有后续写入请求，则会直接将已写入的消息刷到磁盘：使用Erlang的`receive x after 0`实现，只要进程的信箱里没有消息，则产生一个timeout消息，而timeout会触发刷盘操作。

- Queue持久化

  queue的持久化标识durable设置为true，在服务重启之后也会存在，因为服务会把持久化的queue存放在硬盘上。

  `channel.queueDeclare("name", true, false, false, null);`Queue声明时，第二个参数durable=true则表示持久化，第四个参数autoDelete：自动删除，该队列没有任何订阅的消费者的话，自动删除，适用于临时队列。

- Message持久化

  `basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body)`

  消息的持久化取决于发送消息时对消息的设置。body是消息体，最关键的是`BasicProperties`中的`deliveryMode`属性（1：不持久化，2：持久化）

  单单设置消息持久化而不设置队列的持久化显得毫无意义，队列不持久化重启后里面的消息回全部丢失

- Exchange 持久化

  `exchangeDeclare(String exchange, String type, boolean durable)` Exchange声明是，durable= true

###### ACK

消息通过 ACK 确认是否被正确接收，NONE：自动确认（默认）、AUTO：根据情况确认、MANUAL：手动确认。

- 配置：可以通过`spring.rabbitmq`配置方式实现，也可以通过`RabbitListenerContainerFactory`实现配置。
- 需要注意的 basicAck 方法需要传递两个参数
  - **deliveryTag（唯一标识 ID）**：当一个消费者向 RabbitMQ 注册后，会建立起一个 Channel ，RabbitMQ 会用 basic.deliver 方法向消费者推送消息，这个方法携带了一个 delivery tag， **它代表了 RabbitMQ 向该 Channel 投递的这条消息的唯一标识 ID**，是一个单调递增的正整数，delivery tag 的范围仅限于 Channel
  - **multiple**：为了减少网络流量，手动确认可以被批处理，**当该参数为 true 时，则可以一次性确认 delivery_tag 小于等于传入值的所有消息**
- 消息丢失问题
  - rabbitmq 为每一个channel维护了一个delivery tag的计数器，这里采用正向自增，新消息投递时自增，当消息响应时自减；
    在连续收发的场景中，由于消息发送的间隔较短，部分消息因 consumer的重复确认被rabbitmq 当做已处理而丢弃。
  - 消息Json格式转换，`spring.rabbitmq`的手动ACK配置失效，自定义`RabbitListenerContainerFactory` 设置手动ACK

###### 确认机制

publisher-confirms: true 

publisher-returns: true 

- ConfirmCallback

  通过实现 ConfirmCallback#confirm 接口，消息发送到 Broker 后触发回调，确认消息是否到达 Broker 服务器，**也就是只确认是否正确到达 Exchange 中**

- ReturnCallback

  通过实现 ReturnCallback # returnedMessage 接口，启动消息失败返回，比如**路由不到队列**时触发回调

##### kafka

https://juejin.im/post/6844903495670169607#heading-3

###### 基本概念



###### 为什么快

- 顺序读写

  顺序写入磁盘的方式，避免了随机磁盘寻址的浪费

- 零拷贝

  实现了`零拷贝`原理来快速移动数据，避免了内核之间的切换

- 消息压缩

- 分批发送

  Kafka 可以将数据记录分批从生产者到文件系统（Kafka 主题日志）到消费者，减少IO

###### 配置

- 安装配置
  - broker.id（broker唯一表示）
  - log.dir（存放日志片段的目录，逗号隔开）
  - num.recovery.threads.per.data.dir（会使用`可配置的线程池`来处理日志片段）
  - auto.create.topics.enable（kafka 会使用三种方式来自动创建主题，建议设置false）
  - num.partitions = 1 来设置分区数量，默认为1
  - default.replication.factor = 3 设置副本数量
- Spring使用配置

###### 分区 Partition

基本的存储单元，在一个Topic中会有一个或多个Partition，不同partition位于不同的节点，物理上对应一个文件夹。Partition内含一个或多个Segment，每个Segment对应一个数据文件和一个与之对应的索引。Kafka通过不同Partition并行处理提高系统吞吐量，但是不提供统一Partition内不同Segment的并行处理，逻辑上Partition看作一个长数组，通过offset来访问。Partition的数量也不是越多越好，可以通过消费者写Partition吞吐量和消费者消费Partition中消息吞吐量以及目标吞吐量做比较取值。

num.partitions = 1 来设置分区数量，默认为1

###### 复制

Kafka通过zk实现去中心化集群功能，通过副本的复制保证Kafka的整体可用性。Kafka 中消息的备份又叫做 `副本`（Replica），副本的数量是可以配置的，Kafka 定义了两类副本：领导者副本（Leader Replica） 和 追随者副本（Follower Replica），前者对外提供服务，后者只是被动跟随。

default.replication.factor = 3 设置副本数量

###### Kafka Producer

`KafkaProducer producer = new KafkaProducer<String,String>(properties);`

- 创建生产者

  - 首先创建了一个 Properties 对象（参数配置，必要属性bootstrap.server、key.serializer、value.serializer ）
  - 使用 `StringSerializer` 序列化器序列化 key / value 键值对

- 发送消息

  `producer.send(new ProducerRecord<String, String>("topic","key","value"))`

  消息是先被写入分区中的缓冲区中，然后分批次发送给 Kafka Broker。

  - 简单消息

    立即发送，只需要把消息发送到服务端，不关心发送结果

  - 同步消息

    送成功后，send() 方法会返回一个 `Future 对象，Future 对象的类型是 `RecordMetadata` 类型，通过get 可获取发送结果

  - 异步消息

    实现`Callback#onCompletion`接口，生产者接受Kafka服务器响应回执行回调函数

- 分区策略

  - 顺序轮询
  - 随机轮询
  - 按照 key 进行消息保存

- 消息压缩

  Kafka 的消息分为两层：消息集合 和 消息。一个消息集合中包含若干条日志项，而日志项才是真正封装消息的地方。Kafka 底层的消息日志由一系列消息集合日志项组成。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行`写入`操作。

  在 Kafka 中，压缩会发生在两个地方：Kafka Producer 和 Kafka Consumer，为什么启用压缩？说白了就是消息太大，需要`变小一点` 来使消息发的更快一些。

  Kafka Producer 中使用 `compression.type` 来开启压缩

- 发送确认

  **acks** 参数指定了要有多少个分区副本接收消息，生产者才认为消息是写入成功的。此参数对消息丢失的影响较大

  - 如果 acks = 0，发送即成功。
  - 如果 acks = 1，只要集群的 Leader 接收到消息，就会给生产者返回一条消息，告诉它写入成功
  - 如果 acks = all，只有当所有参与复制的节点都收到消息时，才算成功。不过，它的延迟比 acks =1 时更高，因为我们要等待不只一个服务器节点接收消息。

- 消息重发

  retries = 10 重发10次

  retry.backoff.ms  = 1000ms  重试时间每隔1000毫秒

###### Kafka Consumer

采取pull的方式获取，broker无状态，Consumer自己保存offset

- 消费者组

  `消费者组（Consumer Group）`是由一个或多个消费者实例（Consumer Instance）组成的群组，具有可扩展性和可容错性的一种机制。消费者组内的消费者`共享`一个消费者组ID，这个ID 也叫做 `Group ID`，组内的消费者共同对一个主题进行订阅和消费，同一个组中的消费者只能消费一个分区的消息

- 重平衡 Rebalance

  最初是一个消费者订阅一个主题并消费其全部分区的消息，后来有一个消费者加入群组，随后又有更多的消费者加入群组，而新加入的消费者实例分摊了最初消费者的部分消息，这种把分区的所有权通过一个消费者转到其他消费者的行为称为重平衡。

  重平衡的过程对消费者组有极大的影响。因为每次重平衡过程中都会Stop The World。在重平衡期间，消费者组中的消费者实例都会停止消费，等待重平衡的完成。而且重平衡这个过程很慢

- 创建消费则

- 提交偏移量

  `auto.commit.offset` 设置为 false，可以让应用程序决定何时提交偏移量。使用 `commitSync()` 提交偏移量

  - 同步提交

    `commitSync()` 提交偏移量

  - 异步提交

    commitAsync() 提交偏移量

###### 应用

- 用户行为数据
- 日志数据
- 秒杀系统

##### Rocketmq

https://juejin.im/post/6844904008629354504#heading-36

四大核心组成部分：**NameServer**、**Broker**、**Producer**以及**Consumer**，整体框架类似于Dubbo，部署的都是集群，NameServer是个伪集群 。

###### 核心组成

- NameServer

  类似于Dubbo中的Zookeeper，每个NameServer节点互相之间是独立的，无状态的，可以横向扩展，节点之间相互之间无通信，通过部署多台机器来标记自己是一个伪集群。

- Broker

  **Broker**是具体提供业务的服务器，单个Broker节点与所有的NameServer节点保持长连接及心跳，并会定时将**Topic**信息注册到NameServer，顺带一提底层的通信和连接都是**基于Netty实现**的。**Broker**负责消息存储，以Topic为纬度支持轻量级的队列，单机可以支撑上万队列规模，支持消息推拉模型。

- Producer

  **Producer**由用户进行分布式部署，消息由**Producer**通过多种负载均衡模式发送到**Broker**集群，发送低延时，支持快速失败

  **同步发送**：同步发送指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包。一般用于重要通知消息，例如重要通知邮件、营销短信。

  **异步发送**：异步发送指发送方发出数据后，不等接收方发回响应，接着发送下个数据包，一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。

  **单向发送**：单向发送是指只负责发送消息而不等待服务器回应且没有回调函数触发，适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集。

- Consumer

  **Consumer**也由用户部署，支持PUSH和PULL两种消费模式，支持**集群消费**和**广播消息**，提供**实时的消息订阅机制**。

  **Pull**：拉取型消费者（Pull Consumer）主动从消息服务器拉取信息，只要批量拉取到消息，用户应用就会启动消费过程，所以 Pull 称为主动消费型。

  **Push**：推送型消费者（Push Consumer）封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达时执行的回调接口留给用户应用程序来实现。所以 Push 称为被动消费类型，但从实现上看还是从消息服务器中拉取消息，不同于 Pull 的是 Push 首先要注册消费监听器，当监听器处触发后才开始消费消息。

###### 消息领域模型

- Message

- Topic

- Tag

- Group

- Queue

- Offset

- 消息消费模式

  **Clustering**（集群消费）和**Broadcasting**（广播消费）。

  默认情况下就是集群消费，该模式下一个消费者集群共同消费一个主题的多个队列，一个队列只会被一个消费者消费，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费

- Message Order

  Orderly（顺序消费）和Concurrently（并行消费）。

  顺序消费表示消息消费的顺序同生产者为每个消息队列发送的顺序一致，所以如果正在处理全局顺序是强制性的场景，需要确保使用的主题只有一个消息队列。

  并行消费不再保证消息顺序，消费的最大并行数量受每个消费者客户端指定的线程池限制。

###### 完成的通信流程

Producer 与 NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer 获取 **Topic** 路由信息，并向提供 Topic 服务的 **Broker Master** 建立长连接，且定时向 **Broker** 发送心跳。

**Producer** 只能将消息发送到 Broker master，但是 **Consumer** 则不一样，它同时和提供 Topic 服务的 Master 和 Slave建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。

